{
  "projects": [
    {
      "title": "Card Game",
      "slug": "cardgame",
      "date": "2023-10",
      "description": "Building a fullstack React/GraphQL/Django card game",
      "tags": [
        "javascript",
        "python",
        "django",
        "fullstack",
        "graphql",
        "postgres"
      ],
      "content": "## Intro\n\nIn this project, I was interested in working with a new stack, so I took on a project to build a card game with React, GraphQL, Django, and Postgres. This project was a foray into developing the frontend, establishing GraphQL model types, configuring a Django application, and setting up a PostgreSQL database, all containerized with Docker and orchestrated by robust Makefile commands. The project was my first time using Django, GraphQL, and `react-redux`.\n\n[Source code here](https://github.com/rylew2/cardgame) - (full repo available by request)\n\n## Game Rules\n\n- Standard 52-card deck\n- The goal is to end up with the last hand having at least one ace.\n- A dealt hand is 5 cards, and each hand is randomly dealt from the remaining cards in the deck each time the user clicks the `Deal` button.\n - If you successfully make it to the final hand without losing, there will be 2 cards in the hand.\n- The game is \"over\" if all the aces in the deck have been dealt/exhausted before the last hand.\n- The game is considered a \"win\" if the last hand contains at least 1 ace.\n- The game can be replayed as many times as needed‚Äîthere's always a Reset (or `Play Again`) button present.\n- The number of cards left and the number of aces left are displayed at the top.\n\n## Frontend App\n\nI first built the frontend app (without any GraphQL) with all the state (deck, hand, aces left) as in-memory data. The time-consuming part here was setting up all the CSS‚Äîespecially for intricate pieces like the card suit (club/ace/heart/diamond in different orientations), the card animation and rotation, and the overall layout.\n\nThe standalone frontend app is here:\nhttps://card-game-frontend.vercel.app/\n\n### CSS/Design\n\nTo expedite development without perfecting the design, I utilized inline Tailwind utility classes. I'm typically used to a more established design system setup with larger projects, but I found simplifying CSS in this area got me to more of the frontend state management issues faster.\n\nSimilarly, with the animation and rotation‚ÄîI quickly gave a bit of a curve to make the hand look like it was dealt, added some opacity animations as cards were \"dealt\" into place on the board, and added confetti animation (3rd party package) for the win state.\n\n### React/state considerations\n\nAlthough `useState` is often sufficient for small apps, I opted to gain experience with `redux-toolkit`‚Äîso I spent some time reading their [excellent docs](https://redux-toolkit.js.org/tutorials/typescript) to help bootstrap the setup of TypeScript-friendly action creators and a test setup file that made it easy to mock the Redux store so I could test any game state easily.\n\nThe store itself was fairly straightforward with 2 actions (`deal` and `reset`) and 2 reducers with the same names. The `Reset` action simply returns the deck to 47 cards (with 5 having been randomly dealt to the user). `Deal` will try to deal a new hand and determine what state that new hand will confer.\n\nThe store's `deal` reducer:\n\n[code snippet]\n\n### Testing\n\nOnce the Redux store `renderWithProviders` is set up, it becomes really easy to make assertions (using `React Testing Library`) for what's directly on the screen in a given state:\n\n[code snippet]\n\nOr even a simple test that actually clicks things on the screen (I usually define button clicks and actions as their own functions to keep tests compact):\n\n[code snippet]\n\n### If more time allowed for the front end:\n\nWhile I wanted to touch all parts of the stack with this project and not spend a ton of time perfecting the frontend, there are a few areas I wish I had more time to explore:\n\n- Move some of the Tailwind inline classes into CSS files, maybe create app-specific variables for colors and shared styles. As mentioned above, the utility classes were done hastily to reach frontend completion.\n- Animation changes:\n - Fix some of the animation jitter between each hand deal.\n - There's also a known issue when going from a low viewport width to a high width‚Äîit will trigger the animation again. This could likely be stopped with a handleResize-type function preventing repeat animations.\n- I didn't get into any React performance issues with the React Dev tools given this was a small app‚Äîbut you could look at things like `React.memo` or preventing unnecessary re-renders.\n - I added some simple `useCallback` on the click handler functions that get passed down into other components.\n- More robust component library:\n - Creating a reusable `Button` component, for example.\n - Combining the game state components into one shared component (combining `GameWon`, `GameInProgress`, `GameLost`).\n- Pull test helper functions out to a separate file.\n- Exposing `graphqlService` as a hook instead of a service.\n\n## Backend\n\n### Backend overview\n\n- `card` table - stores all 52 cards for a deck.\n - Multiple games could be played with just the 52 cards by resetting status or inserting 52 new entries tied to a new game ID. (I chose the former, but the latter is possible if you wanted to view a prior game's state.)\n- `game` table - simply stores the current status.\n- Mutations => `dealCards(count)`, `resetGame`.\n- Queries => returns `cardsLeftInDeck`, `acesLeftInDeck`, `gameStatus`.\n- The game likely could have been done all in memory‚Äîkind of how the standalone frontend works. Obviously, this wouldn't be durable or support multiple game/streak feature additions.\n\nThe backend work included setting up a DB schema that had a `card` table that stores all 52 cards for a deck, with each card having a suit and rank, and a particular status (`Deck`, `Hand`, or `Discarded`). There's also a simple `game` table that simply stores the game phase (`In Progress`, `Won`, `Lost`, `Loading`)‚Äîthis allows multiple games to be stored. Along with the standard Django tables, this was all that was needed to represent this game on the backend.\n\nFor 3rd normal form, I considered introducing a lookup table for card statuses‚Äîthis would put the status in one place, so it would be easy to rename a status in the future. However, I skipped this normalization step.\n\nMost of the database update functionality was placed in a `GameQueryService`‚Äîa quick collection of static methods that use the Django ORM for querying and updates. A potentially more idiomatic approach would be to embed this logic directly in the models, but I preferred the clean separation and development speed of a dedicated service layer.\n\nI did try to ensure that we weren't doing any database saves in loops, but rather running Django ORM's `bulk_update` after all data updates were made. Although we're dealing with a small amount of data in this app, it's nice to introduce simple improvements along the way that would scale well.\n\n### GraphQL\n\nThe GraphiQL explorer facilitated the setup of the GraphQL API by streamlining query testing. The mutation and resolver files were set up in the `/graphql/types` folder, which are referenced in the `schema.py` file‚Äîthe schema file defines the fields used in mutations or queries.\n\nWriting tests for specific GraphQL queries is also pretty straightforward‚Äîwe simply use a `setUp` method from the built-in `unittest` framework that gets called before each individual test to set up a game. Then it's simply testing the GraphQL query we want (as if coming from the frontend) and making assertions on the returned data.\n\n[code snippet]\n\n### If more time allowed for the back end:\n\n- Define more GraphQL return types‚Äîthis was something that looked like a common GraphQL pattern, just ran out of time here.\n- Further normalize the DB‚Äîmaybe a lookup table for the `card` `status` column.\n - Possibly set up a DB repository pattern.\n- Consider adding a domain layer of pure/deterministic business logic functions.\n- Rate limit some of the API requests‚Äîi.e., I believe resetting the DB too quickly can cause issues (if the user clicks reset one too many times).\n- Install `ptw` to watch and rerun tests more easily.\n- Following GraphQL best practices, it would be more idiomatic to use nested fields.\n\n## Putting it all together\n\nAfter ensuring the frontend and backend worked and were fully tested, I followed a few steps to integrate the full-stack application:\n\n- Installing Apollo and pointing the client to the GraphQL address in `index.tsx`.\n\n[code snippet]\n\n- Removing the frontend in-memory storage and instead referencing the GraphQL returned data.\n- I set up a `codegen` file using the `@graphql-codegen/cli` that would take the GraphQL types defined on the backend and generate a set of TypeScript types that I could use on the frontend. This required me to go back and update a lot of the frontend enums and utility functions with those types.\n\n## Conclusion\n\nWorking with familiar languages while learning new frameworks and libraries was an engaging experience. There are a few final next steps I was considering:\n\n### Additional items if more time allowed for the project:\n\n- Set loading state prior to GraphQL calls (and between deals/resets)‚Äîalthough it's pretty quick to make a mutation and get the result, it might make sense to have the loader show momentarily.\n- E2E tests‚Äîit would have been nice to add some Playwright tests to get additional behavioral coverage.\n- Data fetching‚ÄîI didn't have time to get into it, but there is `Redux Toolkit Query` and I would be curious how that might overlap, enhance, or work in combination with GraphQL and the Apollo client.\n- Synchronizing the backend database state with the Redux store felt somewhat redundant; relying solely on the backend might suffice for this type of app. However, I kept Redux to gain experience with `redux-toolkit`.\n- Deploy the full-stack app to Vercel (it works fine locally for now)‚Äîright now just the frontend is deployed, though it functions exactly the same as the full-stack app."
    },
    {
      "title": "Exploring VueJS",
      "slug": "exploring-vue",
      "date": "2021-07",
      "description": "Trying out VueJS with the NASA API",
      "tags": [
        "vue",
        "javascript"
      ],
      "content": "Exploring VueJS was intriguing, given its rising popularity and parallels with React's growth trajectory. Vue provides options to scale using superhero frameworks like [Nuxt.js](https://nuxtjs.org/) and state management tools like [Vuex](https://vuex.vuejs.org/).\n\nWhile the 2020 front-end framework survey indicates React is still in the lead, if you look at GitHub stars, the Vue repo actually has the most love. React was likely able to make a big impact earlier due to Facebook's support, but given that Vue is not backed by a tech giant, it's done remarkably well for itself.\n\n## Building a simple NASA API Vue App\n\nFor this project, I wanted to quickly build out a Vue app that would make a simple API call and display data in an easy-to-understand way. I ended up choosing the Near Earth Object Web Service from [NASA's Open API](https://api.nasa.gov/). This web service lets you search for asteroids based on their closest approach date to Earth‚Äîalong with a bevy of metadata such as the size of the asteroid and whether or not it‚Äôs deemed hazardous. When first seeing the results from the API, it was amazing to see just how many near-earth asteroids are out there‚Äîit really is a cosmic shooting gallery out in space.\n\nThe way I set up this project was first to choose the Vue version‚Äîwith the newer Vue 3 supporting a new `Composition API`. While Vue 2 uses the `Options API`, which utilizes the `data`, `methods`, and `mounted` functions, for example, [Vue 3](https://markus.oberlehner.net/blog/vue-3-composition-api-vs-options-api/) utilizes a single `setup` hook that makes it [easier to share code among components](https://markus.oberlehner.net/blog/vue-3-composition-api-vs-options-api/).\n\nBecause this was a quick and dirty app and I wanted to focus on the Vue basics, I opted to go for Vue 2. Since I've used Bootstrap quite a bit before, I decided to opt for Vuetify‚Äîthe Material Framework for Vue.\n\nThe `Home` route of the app simply has choices for the Start and End Date (which must be within 7 days of each other) and displays a list of the identified near-earth asteroids for that date range. The results are paginated in a Vuetify table.\n\nYou can browse to the `Detail` route if you click on any row in the table. The detail route includes the NASA Picture of the Day and a Vuetify vertical tab set that has some details such as the size of the asteroid and its closest approaches. While the data on the home route includes multiple asteroids from the NASA NEO Feed endpoint, the data generated in the Detail route includes info from a separate NEO Lookup endpoint.\n\n## Learning Vue ‚Äî from a React perspective\n\nSome of the design choices from React‚Äîlike lifting state up and keeping custom components at the top of the component hierarchy (putting your pure presentational components towards the leaves of the hierarchy)‚Äîtranslate well to Vue. An example of that code is below:\n\n[code snippet]\n\n_Primarily custom components like Home are at the top of the component hierarchy._\n\n### Using Vue-specific features\n\nI only scratched the surface of framework-specific Vue features‚Äîsuch as the `watch` method and emitting `$event`s‚Äîthese are not something you see in React.\n\nI ended up using the `$event` emitter to pass events from child back up to parent components. Typically in React, you might do this by passing a prop down as a function. And if this project were larger, you might consider using something like Vuex.\n\nAnother feature I wish I had tried was `v-model`, which is quite similar to an Angular `ng-model`. Vue's (and Angular's) two-way binding system is different from React's one-way binding‚Äîfor example, in React, you usually have to call an event handler for an input update to affect state, whereas with Vue, the framework's watchers take care of this behind the scenes.\n\n### React vs Vue\n\nThere are a lot of similarities between the two‚Äîsuch as the core libraries being complemented by separate companion libraries that handle routing and global state management. They both utilize a virtual DOM. They both promote modular, reusable, and composable components.\n\nThere are some nuanced differences though‚Äîthey include:\n\n- **Optimizing re-renders** \n React uses `PureComponent` or `shouldComponentUpdate` to prevent unnecessary re-renders‚Äîthe downside being all child components are dependent on a parent with one of these optimizations. All Vue components have a `shouldComponentUpdate` equivalent‚Äîsimplifying the nested component caveats. Vue says this removes the need for performance optimization concerns for Vue apps‚Äîallowing developers to focus on building the app itself.\n\n- **React's JSX focus versus Vue templates** \n React's JSX allows you to use the full power of JS (vars, flow control, tooling) in your view (render function). While Vue also has a render function and supports JSX, the template is deemed a simpler alternative‚Äîit is much easier to learn for those more familiar with HTML such as designers. Since Vue still allows for logical components that use JSX, Vue allows us to use both.\n\n- **React `styled-components` versus Vue's single-file component \"scoped\" style** \n Vue favors the default method using a simple `` tag in single-file components.\n\n- **The `Vue CLI` offers additional features over `create-react-app`** \n `create-react-app` does not allow configuration during project setup while the Vue CLI does, and it can be extended via plugins. Furthermore, the Vue CLI has the added feature of allowing a project to be defined from presets‚Äîa JSON object that has predefined options/plugins for a new project.\n\n- **Vue doesn't favor/require ES6, JSX, or build-systems** \n Vue can simply be run by including a script tag (``) and writing Vue code without the need for performance concerns. Therefore, the docs suggest that Vue can scale both up and down‚ÄîReact is more difficult for minimal deployments.\n\n- **Vue native rendered support is still in its infancy** \n While React Native still likely takes the cake here for its native rendering using the same React component model, Vue's [`Weex`](https://github.com/alibaba/weex) cross-platform UI framework has been gaining momentum.\n\n### Some testing sprinkled in\n\nI experimented with `vue-test-utils` and plan to revisit it after completing Kent Dodds' Testing JavaScript course. Since `vue-test-utils` comes with both unit and e2e test folder structures out of the box, I decided to write a few basic test cases.\n\nThis was the first time I had ever used Cypress, and it's a pretty stellar tool. I like seeing visual representations of my work‚Äîtherefore seeing the Cypress robot run is pretty satisfying and a good Selenium replacement. While Cypress only runs with JavaScript, has difficulty handling events like file uploads or hover, and doesn't support mobile testing, these disadvantages are outweighed by the good parts: snapshots, readable stack traces, ability to wait during test execution, and cross-browser testing."
    },
    {
      "title": "Building a React SharePoint starter kit",
      "slug": "sharepoint-react",
      "date": "2020-06",
      "description": "Building a template to deploy React solutions built on top of SharePoint.",
      "tags": [
        "react",
        "javascript"
      ],
      "content": "`SharePoint`, Microsoft's enterprise content management platform, enables teams to collaborate on files, workflows, and resources. Its extensibility varies based on the SharePoint version and site type‚Äîranging from simple in-page web parts to the React-based [SPFx development model](https://docs.microsoft.com/en-us/sharepoint/dev/spfx/sharepoint-framework-overview).\n\nOftentimes, we would allow users to manage their own data in one or more SharePoint Lists that would serve as the backend for a React UI frontend. When deploying these types of apps, we would often run into a couple of situations where:\n\n1. Defining the look and feel without editing the Master Page/Page Layout.\n2. Rapidly iterating on a React single-page app if SPFx wasn't available.\n3. Deploying a CRA build folder to SharePoint automatically via CLI.\n\nThis led to creating a starter kit based on Create React App (CRA) to iterate and deploy quickly to SharePoint. Starting from the basic CRA template, I will walk through some of the key configuration steps to achieve a more seamless SharePoint development workflow that is able to pull in data.\n\n## Setting up the Proxy Server\n\nTo make localhost requests to SharePoint Lists (avoiding CORS issues), proxy API calls using [`sp-rest-proxy`](https://www.linkedin.com/pulse/getting-started-react-local-development-sharepoint-andrew-koltyakov/) by [@koltyakov](https://github.com/koltyakov).\n\nThe configuration here was largely based on the great work shown here‚Äîsetting up a [SharePoint API proxy server using his `sp-rest-proxy` package](https://www.linkedin.com/pulse/getting-started-react-local-development-sharepoint-andrew-koltyakov/). This allows a webpack dev server and a proxy API server to run concurrently. I recommend completing that simple walkthrough first‚Äîonce you have that set up, you should have the following file:\n\nExample `api-server.js`:\n\n[code snippet]\n\nAdd a `proxy` script in `package.json`:\n\n[code snippet]\n\n> **Tip:** Add `./config/private.json` to `.gitignore`.\n\nWith `concurrently` and a `startServers` script added to `package.json`, run both servers together with `npm run startServers`.\n\nTest it by visiting `localhost:8081`.\n\n## Making API Calls\n\nTo make an API call, we're simply using the `@pnp/sp` package (the documentation for [PnPJS accessing lists is pretty good](https://pnp.github.io/pnpjs/sp/lists/)).\n\nThere are a couple of ways to approach the initial setup of the PnPJS package‚Äîbut here I'm using the `sp.setup()` one-time call in my App `componentDidMount`; it could similarly be done in a Nav component.\n\n[code snippet]\n\nWe can also set environment variables in our project in a `.env` file:\n\n[code snippet]\n\nAfter the `sp.setup` call, we should be able to make List API calls anywhere in our app:\n\n[code snippet]\n\n## Automate Deployment\n\nInstead of manually uploading the build folder, I wrote [`upload.js`](https://github.com/rylew2/sharepoint-cra-starter/blob/master/deploytools/upload.js), which:\n\n1. Deletes `/static/js` if it exists (uses `sppurge`).\n2. Uploads & overwrites the build folder (`spsave`).\n\nTo run this upload script, we would need to add `gulp`, `spsave`, and `sppurge` to the `devDependencies`. Once those packages are in place, you should be able to at least attempt the upload to SharePoint with the following added to `package.json` scripts:\n\n[code snippet]\n\nYou can optionally define a second upload script to point to your UAT site.\n\n## Fixing Tilde in Build Folder Files for SP2013\n\nOne of the catches here when working specifically with SP 2013 is that it does not allow filenames with tilde `~` characters to be uploaded to the site. To address this, we could eject CRA and configure it manually, but using the [`rescripts`](https://github.com/harrysolovay/rescripts) package was a simpler alternative. The more popular [`react-app-rewired`](https://github.com/timarney/react-app-rewired#readme) or [`craco`](https://github.com/gsoft-inc/craco) packages might have done the job here; however, I ended up using `rescripts`.\n\nWhen trying to upload the project, you might run into an issue like this:\n\n> The file or folder name \\\\\\\"MyProject/static/js/runtime~main.d653cc00.js\\\\\\\" contains invalid characters. Please use a different name. Common invalid characters include the following # % & \\* : ? / { | }\n\nYou therefore need to add the rescripts package to `devDependencies` and create a `./rescriptsrc.json` file:\n\n[code snippet]\n\n[code snippet]\n\nAt this point, when we run `npm run upload`, we should be able to successfully save/upload all files to our SharePoint specified folder. You won't be able to view this uploaded folder through the traditional site contents‚Äîyou'll need to view it using SharePoint Designer. It should be sitting as a folder at the root of the site.\n\n## Routing with the HashRouter\n\nWhen we upload to SharePoint, the app needs to simply run for users from `./index.html` without a server. Routing simply does not work like this from the build folder out of the box. Therefore, we need to use [`HashRouter`](https://reactrouter.com/web/api/HashRouter). This will add a `#` character to all of our routes. The more traditional `BrowserRouter` uses the HTML5 History API and is the preferred route when using a server or server-side rendering.\n\nAssuming you have `react-router-dom` installed, the simple routing setup (which I've included in my repo) looks like the following:\n\n[code snippet]\n\n[code snippet]\n\nThe final configuration step for HashRouter is to specify the homepage in `package.json`:\n\n[code snippet]\n\n## IE11 Legacy Support\n\nTo support the older IE11 browser, simply install the `react-app-polyfill` package and include it in `index.js`:\n\n[code snippet]\n\n## Deploying\n\nWith all the primary configuration done, we can define our deploy scripts (UAT again is optional) in `package.json`:\n\n[code snippet]\n\nThen running `npm run deploy` will regenerate our `./build` folder, delete the old build folder on the SharePoint folder, and upload the new build folder files.\n\nUsers can then simply be given the URL to the index.html file, i.e.:\n\n> http://my-sharepoint-prod.com/sites/mysite/MyProjectFolder/index.html\n\nTheir permissions to the site will simply be set at the site level.\n\n## Summary\n\nCheck the [full `package.json`](https://github.com/rylew2/sharepoint-cra-starter/blob/master/package.json). With this starter kit, you can:\n\n- Build & upload a React app to SharePoint.\n- Make API calls from localhost and deployed environments.\n- Use routing without an HTTP server.\n\nThe project's aim was to focus on building a React app that leveraged SharePoint List data, avoiding traditional SharePoint development complexities. The end result for our team was being able to more rapidly iterate and deploy solutions‚Äîand ultimately being able to focus more on our clients' needs.\n\nThere is probably additional work or possible improvements that could be made‚Äîsuch as converting to TypeScript, Dockerizing, or integrating with other automations on a CI/CD tool. You might even include a suite of domain-specific tests against SharePoint List data. Feel free to make pull requests or raise issues on the repo. I hope this guide has helped‚Äîit turned out to be quite useful for some of my work projects."
    },
    {
      "title": "Machine Learning Part 4: Markov Decision Processes & Reinforcement Learning",
      "slug": "ml-part-4-reinforcement-learning",
      "date": "2019-06",
      "description": "Exploring Value Iteration, Policy Iteration, and Q-Learning in stochastic grid worlds, comparing convergence, rewards, timing, and behavior across easy and hard MDP environments.",
      "tags": [
        "python",
        "reinforcement learning",
        "mdp",
        "value iteration",
        "policy iteration",
        "q-learning",
        "omscs"
      ],
      "content": "In this assignment I moved from supervised and unsupervised learning into the world of **sequential decision making**. Using two grid-world environments, I compared three core algorithms for solving **Markov Decision Processes (MDPs)**:\n\n- **Value Iteration (VI)**\n- **Policy Iteration (PI)**\n- **Q-Learning** (model-free reinforcement learning)\n\nThe goal was to understand how these algorithms behave as the environment becomes more complex: how quickly they converge, how good their final policies are, and how much computation they require.\n\n---\n\n## üìò MDP Overview\n\nAn MDP is defined by:\n\n- **States (S):** all possible agent locations in the grid\n- **Actions (A):** up, down, left, right\n- **Transition function (T):** probability of landing in next state s‚Ä≤ after action a\n- **Rewards (R):** numeric feedback for entering states (good or bad)\n\nValue Iteration and Policy Iteration assume that T and R are known.\n**Q-Learning**, in contrast, never sees the model and instead learns purely from trial-and-error interaction.\n\nThe **discount factor Œ≥** controls how much the agent values the future:\n\n- High Œ≥ (around 0.99) encourages long-term planning toward the goal.\n- Low Œ≥ makes the agent shortsighted, caring mostly about immediate rewards.\n\n---\n\n## üåç Grid-World Environments\n\nI used two grid-worlds that share the same reward structure but differ in scale and difficulty.\n\n### Easy Grid World (10√ó10)\n\n- White cells: small negative reward (‚àí1) to encourage reaching the goal quickly\n- Colored cells: harsher penalties (‚àí10, ‚àí30, ‚àí50)\n- Top-right cell: terminal state with reward +100\n- A few walls to bend the path but not make it too maze-like\n\n### Hard Grid World (20√ó20)\n\n- Much larger map with many more walls and bottlenecks\n- More frequent and severe negative reward regions\n- Many more distinct paths to the goal ‚Äì and many more bad ones\n\nBoth worlds are **stochastic**: the intended action happens 80% of the time, and each of the other three directions occurs about 6.67% of the time. Even a good policy must be robust to occasional slips.\n\n---\n\n## üü¶ Dynamic Programming: Value Iteration vs Policy Iteration\n\nValue Iteration and Policy Iteration both assume a full model of the environment and aim to compute an optimal policy, but they do it in different ways.\n\n- **Value Iteration** repeatedly applies the Bellman backup to update state values until they stop changing. The policy is implicitly ‚Äúgreedy‚Äù with respect to these values.\n- **Policy Iteration** alternates between:\n 1. **Policy evaluation** ‚Äì computing values for the current policy\n 2. **Policy improvement** ‚Äì updating the policy to be greedy with respect to those values\n\n### Easy World\n\nOn the smaller grid, both algorithms converge quickly to the same intuitive strategy: weave around high-penalty cells while heading toward the +100 terminal state.\n\nSome observations:\n\n- **Policy Iteration converges in fewer iterations**, because each iteration does a full policy evaluation step.\n- Those iterations are **more expensive**, so total runtime is closer than the iteration counts suggest.\n- Higher Œ≥ values emphasize the +100 goal state more strongly, making the agent tolerate short detours through mildly bad states if they lead to a shorter overall route.\n\nTo visualize how values propagate, I plotted both **value maps** and **policy arrows** over iterations. Early on, everything is red and noisy; as iterations progress, blues spread outward from the goal and arrows line up to form clean paths.\n\n### Hard World\n\nThe 20√ó20 world tells a different story.\n\n- Convergence takes significantly longer because there are many more states and many more ways to accumulate negative reward on the way to the goal.\n- VI tends to improve more **gradually and smoothly**, as each sweep softly updates values everywhere.\n- PI shows sharp spikes early on as new policies radically redirect the agent through different parts of the maze.\n- With **low Œ≥**, both algorithms effectively give up on reaching the goal ‚Äì the future +100 is discounted so heavily that staying near safer regions looks preferable.\n\nThe final policy in the hard world still manages to thread a narrow path through the maze of penalties:\n\n---\n\n## ‚ö° Q-Learning ‚Äì Model-Free Reinforcement Learning\n\nUnlike VI and PI, **Q-Learning** does not require knowing T or R in advance.\nIt instead learns **action-values** Q(s, a) directly by interacting with the environment:\n\nQ(s, a) ‚Üê (1 ‚àí Œ±)Q(s, a) + Œ± [R + Œ≥ max‚Çê‚Ä≤ Q(s‚Ä≤, a‚Ä≤)]\n\nLearning depends heavily on three hyperparameters:\n\n- **Learning rate (Œ±)** ‚Äì how much new information overrides old estimates\n- **Exploration rate (Œµ)** ‚Äì probability of taking a random action\n- **Initial Q-values** ‚Äì optimistic vs neutral starting assumptions\n\n### Easy World: Hyperparameter Experiments\n\nIn the 10√ó10 grid I varied Œµ, Œ±, and the initial Q values.\n\nKey findings:\n\n- **Œµ = 0.1** struck the best balance between exploration and exploitation ‚Äì enough random moves to discover the map, but not so many that the agent thrashes forever.\n- Very high Œµ values produce noisy reward curves, as the agent keeps revisiting bad states.\n- **Œ± = 0.1** provided stable learning; large Œ± (0.9) caused Q-values to overshoot and oscillate.\n- Neutral initial values (Q = 0) worked better than overly optimistic ones, which tempted the agent to wander too long before committing to good paths.\n\nOver time the learned policy converges to the same path as the dynamic-programming methods, but it takes many more interactions to get there.\n\n### Hard World: More States, More Trouble\n\nIn the hard 20√ó20 grid, the same trends hold but are amplified:\n\n- Bad choices are more costly because they often lead into long corridors of negative rewards.\n- Higher Œµ means the agent is more likely to get ‚Äúlost‚Äù for long stretches in punishing regions.\n- Again, Œ± = 0.1 and Œ≥ = 0.99 produced the most reliable learning. Lower Œ≥ values drastically undervalued the terminal reward and resulted in policies that barely tried to reach the goal.\n\nDespite the difficulty, Q-Learning still discovers a reasonable path given enough iterations, showcasing its ability to learn **without ever seeing the model**.\n\n---\n\n## üìè Scaling Up: Variable Grid Size\n\nFinally, I looked at how the algorithms behave as the grid grows to n√ón.\n\nAs expected:\n\n- All methods require **more steps** to reach the goal as n increases.\n- Negative rewards accumulate more easily because there are more ways to wander.\n- For Q-Learning, reward curves drop sharply around **n = 40**, suggesting that naive exploration becomes insufficient in very large spaces.\n- In terms of **time per iteration**:\n - Q-Learning is by far the **fastest** update step.\n - Value Iteration sits in the middle.\n - Policy Iteration is **slowest**, since each iteration performs a full policy evaluation sweep.\n\n---\n\n## üìù Summary Table\n\nFrom the experiments I summarized convergence and timing across algorithms:\n\n| Algorithm | World | Iterations to Converge | Converged Reward | Converged Steps | Time/Iter | Total Time |\n|-----------------|-------|------------------------|------------------|-----------------|-----------|-----------|\n| Value Iteration | Easy (Œ≥=0.99) | **25** | 60 | 36 | 0.005621 | 0.140525 |\n| Value Iteration | Hard (Œ≥=0.99) | 37 | 16 | 60 | 0.01892 | 0.69934 |\n| Policy Iteration | Easy (Œ≥=0.99) | **10** | **60** | **36** | 0.033461 | 0.33461 |\n| Policy Iteration | Hard (Œ≥=0.99) | **12** | **60** | **60** | 0.107643 | 1.5266 |\n| Q-Learning | Easy (Œ±=0.1, Œµ=0.1, Œ≥=0.99) | 154 | 60 | 36 | **0.000172** | **0.026488** |\n| Q-Learning | Hard (Œ±=0.1, Œµ=0.1, Œ≥=0.99) | 880 | 45 | 75 | **0.000352** | **0.3098** |\n\nBest values are bolded. Q-Learning is by far the cheapest per update, but often needs many more updates to reach comparable performance.\n\n---\n\n## üß© Final Takeaways\n\n**Value Iteration**\n\n- Very stable and conceptually simple.\n- Converges reliably without dramatic swings in value.\n- In the hard world it ends up faster overall than Policy Iteration, thanks to cheaper iterations.\n\n**Policy Iteration**\n\n- Needs the **fewest iterations** to converge.\n- Each iteration is expensive due to full policy evaluation.\n- Produces slightly better final policies in some settings, especially when Œ≥ is high.\n\n**Q-Learning**\n\n- Most flexible: does not require a model of the environment.\n- Fastest update step, but potentially many more updates.\n- Highly sensitive to Œ±, Œµ, and initialization.\n- More prone to local minima and high variance early in training, especially in large or heavily penalized worlds.\n\n---\n\n## üß† Big Picture\n\nAcross these experiments, no single method dominates:\n\n- **VI** is steady and dependable when you have a known model.\n- **PI** can converge in fewer iterations but at a higher computational cost per sweep.\n- **Q-Learning** shines in **model-free** settings, as long as its hyperparameters are tuned carefully.\n\nThis assignment is a concrete example of the **No Free Lunch Theorem** in reinforcement learning: the ‚Äúbest‚Äù algorithm depends on the environment, reward structure, and what information you have about the world. Understanding the domain is just as important as choosing the algorithm."
    },
    {
      "title": "Machine Learning Part 3: Unsupervised Learning & Dimensionality Reduction",
      "slug": "ml-part-3-unsupervised",
      "date": "2019-06",
      "description": "Exploring clustering, Gaussian mixtures, and dimensionality reduction methods (PCA, ICA, RP, RF) on the Wine and Abalone datasets.",
      "tags": [
        "python",
        "sklearn",
        "machine learning",
        "clustering",
        "dimensionality reduction",
        "omscs"
      ],
      "content": "1Ô∏è‚É£ [Part 1: Supervised Learning & Neural Networks](/projects/ml-part-1-supervised)\n\n2Ô∏è‚É£ [Part 2: Randomized Optimization](/projects/ml-part-2-randomized-optimization)\n\n3Ô∏è‚É£ **Part 3: Unsupervised Learning & Dimensionality Reduction**\n\n4Ô∏è‚É£ (Coming soon)\n\n## Introduction\n\nUnlike supervised learning‚Äîwhere models learn from labeled examples‚Äî**unsupervised learning aims to uncover patterns in data without any ground-truth labels**. The goal is to find natural groupings, meaningful structure, or lower-dimensional representations hidden inside high-dimensional datasets.\n\nIn this part of the Machine Learning series, I focused on two major unsupervised learning themes:\n\n### üß© 1. Clustering Algorithms\nClustering groups similar data points based on their position in feature space.\nThe project evaluates two core methods:\n\n- **K-Means** ‚Äî partitions points into \\(k\\) compact clusters by minimizing distance to cluster centroids.\n- **Gaussian Mixture Models (GMM)** ‚Äî a probabilistic approach that models the data as a mixture of Gaussians, allowing soft membership and more flexible cluster shapes.\n\nThese methods help answer:\n\n- *Do natural subgroups exist in this dataset?*\n- *How well separated‚Äîor overlapping‚Äîare the clusters?*\n\n### üîª 2. Dimensionality Reduction\nDimensionality reduction (DR) transforms the data into a smaller set of informative features, often revealing structure that clustering alone can‚Äôt capture.\nThe techniques explored include:\n\n- **PCA** ‚Äî captures directions of highest variance\n- **ICA** ‚Äî separates independent latent signals\n- **Random Projection** ‚Äî compresses features while preserving distances\n- **Random Forest feature selection** ‚Äî keeps only the most informative features\n\nThese DR methods are then combined with clustering‚Äîand later, a neural network‚Äîto evaluate how reduced representations affect performance.\n\nTwo datasets were used:\n\n- üç∑ **Wine Quality** ‚Äî chemical properties predicting quality\n- üêö **Abalone** ‚Äî physical measurements predicting age\n\n---\n\n## Part 1: Baseline Clustering Performance\n\nBefore applying dimensionality reduction, I evaluated how K-Means and GMM perform on the **raw datasets**.\n\nA consistent pattern emerged:\nAs the number of clusters increases, the **silhouette score** ‚Äî which measures how well a point fits within its own cluster compared to the nearest other cluster ‚Äî tends to drop, since clusters naturally become more compressed.\n\n### Abalone ‚Äì Baseline Silhouette Scores\n\n---\n\n## Part 2: Dimensionality Reduction\n\nEach dimensionality reduction method reshapes the feature space differently:\n\n- **PCA** rotates the data to maximize variance retention\n- **ICA** attempts to separate independent signals\n- **Random Projection (RP)** compresses dimensionality with JL guarantees\n- **Random Forest (RF)** selects features based on importance (Gini)\n\nThe goal was to see whether these transforms help clustering uncover more meaningful patterns, or reduce noise that might blur cluster boundaries.\n\n---\n\n## üìâ t-SNE Visualization (Exploratory)\n\nAlthough not used directly for clustering or neural networks, **t-SNE (t-Distributed Stochastic Neighbor Embedding)** is a nonlinear technique for **visualizing high-dimensional structure in 2D**.\nIt preserves local relationships, making it useful for checking whether a dataset has visually separable clusters before performing formal analysis.\n\n### Example ‚Äì Abalone t-SNE 2D Plot\n\nt-SNE reveals why Abalone is difficult to cluster:\n**the classes heavily overlap**, even under a nonlinear embedding. This visual intuition aligns with the modest improvements seen from PCA, RP, and RF later in the analysis.\n\n---\n\n## Part 3: Clustering on Reduced Dimensions\n\n### Wine ‚Äì Silhouette Score Comparison\n\nRandom Projection surprisingly produces the most distinct clusters early on, likely because it breaks noisy feature correlations.\n\n### Abalone ‚Äì Silhouette Score Comparison\n\nAbalone is noisier and lower-dimensional, so improvement is more modest, but ICA consistently underperforms.\n\n---\n\n### Wine ‚Äì K-Means Cluster Label Accuracy\n\nRandom Forest feature selection slightly outperforms other DR methods, suggesting that filtering noisy features helps more than rotating or projecting them.\n\n---\n\n## Part 4: GMM Performance on Reduced Data\n\nGaussian Mixture Models capture cluster shape better than K-Means, especially where clusters overlap ‚Äî like in the Wine dataset.\n\n### Wine ‚Äì GMM Label Accuracy\n\nRF again yields the strongest or near-strongest accuracy across cluster sizes.\n\n---\n\n## Part 5: Abalone ‚Äì DR Performance Highlights\n\nWhile Wine benefits noticeably from DR, **Abalone is lower-dimensional and noisier**, meaning differences across DR methods were smaller.\n\nThe one clear takeaway:\n**ICA consistently performs the worst**, both in silhouette and label accuracy.\n\n### Abalone ‚Äì Silhouette Comparison With DR\n\nVisible struggle from ICA compared to PCA, RP, or RF.\n\n---\n\n## Part 6: Neural Network Performance on DR + Cluster Features\n\nI trained a small neural network using:\n\n- Original features\n- PCA-reduced features\n- ICA-reduced features\n- RP-reduced features\n- RF-selected features\n- Cluster assignments as features (K-Means labels)\n\nTwo key observations:\n\n1. **RF-selected features almost always gave the best NN test accuracy.**\n Removing noisy or irrelevant inputs proved more effective than transforming all features.\n\n2. **Cluster labels as features** yielded the **fastest runtime** but weaker accuracy, since cluster IDs alone discard too much information.\n\n### Abalone ‚Äì NN Performance on DR Feature Sets\n\n### Abalone ‚Äì NN Mean Fit Time\n\n---\n\n## Conclusion\n\nAcross both datasets, dimensionality reduction had **mixed but insightful effects**:\n\n### üîπ Wine Dataset üç∑\n\n- **RF feature selection** provided the strongest results for both K-Means and GMM.\n- **Random Projection** produced the highest silhouette scores early on.\n- Dimensionality reduction clearly improved cluster stability and separability.\n\n### üîπ Abalone Dataset üêö\n\n- Much **less improvement** across techniques ‚Äî the dataset is noisy and nearly low-dimensional already.\n- **ICA performed the worst** across all metrics.\n- RF and PCA showed small but consistent gains.\n\n### üîπ Neural Networks on Reduced Data\n\n- **RF-selected features** delivered the best test accuracy.\n- **Cluster labels** were extremely fast but cost accuracy.\n\n### üß† Final Takeaway\n\nThis part of the project reinforced the No Free Lunch Theorem:\n**No single dimensionality reduction method is universally best.**\n\nPerformance depends heavily on dataset structure:\n\n- üç∑ Wine‚Äôs correlated chemical signals ‚Üí DR reveals clearer structure\n- üêö Abalone‚Äôs noisy, compact feature space ‚Üí limited benefit from DR"
    },
    {
      "title": "Machine Learning Part 2: Randomized Optimization",
      "slug": "ml-part-2-randomized-optimization",
      "date": "2019-06",
      "description": "A practical look at Random Hill Climbing, Simulated Annealing, Genetic Algorithms, and MIMIC applied to neural network weight tuning and classic optimization problems.",
      "tags": [
        "machine learning",
        "optimization",
        "randomized algorithms"
      ],
      "content": "1Ô∏è‚É£ [Part 1: Supervised Learning & Neural Networks](/projects/ml-part-1-supervised)\n\n2Ô∏è‚É£ **Part 2: Randomized Optimization**\n\n3Ô∏è‚É£ [Part 3: Unsupervised Learning & Dimensionality Reduction](/projects/ml-part-3-unsupervised)\n\n4Ô∏è‚É£ (Coming soon)\n\n## Introduction\n\nRandomized Optimization (RO) is a powerful alternative when traditional gradient-based methods fall short ‚Äî especially when the fitness function is not differentiable or the search space is rugged and full of local optima. In this project, I explored four classic RO algorithms ‚Äî **Random Hill Climbing**, **Simulated Annealing**, **Genetic Algorithms**, and **MIMIC** ‚Äî applied to two challenges:\n\n1. **Tuning neural network weights**\n2. **Solving three well-known optimization problems: Continuous Peaks, Flip Flop, and the Traveling Salesman Problem (TSP)**\n\n---\n\n## Part 1: Neural Network Weight Tuning\n\nBefore tackling standalone optimization problems, I tested how well RO can tune neural network weights compared to traditional backpropagation with gradient descent.\n\n---\n\n### Backpropagation / Gradient Descent\n\nAs a baseline, I trained a neural network with three hidden layers of 22 nodes each using backpropagation. This classic method computes the gradient of the cost function and updates weights accordingly. As expected, the training error converged quickly within 100‚Äì200 iterations, with test accuracy stabilizing around 76%.\n\n---\n\n### Random Hill Climbing (RHC)\n\nRHC starts with a random guess for weights and iteratively tweaks them to find better configurations. To avoid getting stuck in local optima, I used random restarts. Despite this, RHC required about 1000 iterations to converge ‚Äî much longer than backpropagation ‚Äî highlighting the challenge of small attraction basins.\n\n---\n\n### Simulated Annealing (SA)\n\nSimulated Annealing is inspired by metallurgy: it allows occasional downhill steps to escape local optima, controlled by a temperature parameter. I tested different cooling rates and observed that higher rates (slow cooling) sometimes led the network to wander into higher-error regions. Overall, SA showed reliable convergence but required careful tuning to balance exploration and exploitation.\n\n---\n\n### Genetic Algorithm (GA)\n\nThe GA treats weight configurations as \"individuals\" in a population. It evolves them over generations using selection, crossover, and mutation. I varied population sizes and mate/mutation pairs, finding that larger populations boost diversity and performance but also increase runtime. GA often showed more volatile convergence due to its exploratory nature.\n\n---\n\n### Part 1 Comparison\n\nOverall, backpropagation remains the fastest and most reliable for weight tuning. Among the RO methods, RHC and SA converged faster than GA, but all lagged behind gradient descent in both time and final accuracy.\n\n---\n\n## Part 2: Solving Classic Optimization Problems\n\nNext, I applied all four RO algorithms to three classic optimization problems: Continuous Peaks, Flip Flop, and the Traveling Salesman Problem (TSP).\n\n---\n\n### Continuous Peaks\n\n**Problem:** Maximize the reward for having long contiguous sequences of 0s or 1s in a bit string, with an extra bonus if both exceed a threshold.\n\nKey observations:\n\n- **RHC:** Multiple restarts helped cover the search space but convergence varied by trial.\n- **SA:** Best results with moderate cooling rates; high rates wandered too much.\n- **GA:** Showed oscillating fitness but steadily improved.\n- **MIMIC:** Captured problem structure well for smaller instances but required more computation for larger N.\n\n---\n\n### Flip Flop\n\n**Problem:** Maximize the number of alternating bits in a bit string (e.g., 010101...).\n\nRHC and SA reliably climbed to high fitness. GA fluctuated near convergence due to crossover mutations. MIMIC needed many evaluations and didn‚Äôt outperform SA here but showed promise with more tuning.\n\n---\n\n### Traveling Salesman Problem (TSP)\n\n**Problem:** Find the shortest path visiting each \"city\" exactly once and returning to the start.\n\nGiven its NP-hard nature, TSP challenged all algorithms:\n\n- **RHC & SA:** Got stuck in local optima more often due to the huge combinatorial space.\n- **GA:** Outperformed the others by maintaining a diverse population of routes.\n- **MIMIC:** Surprisingly underperformed, likely due to parameter settings and the complexity of modeling dependencies in valid paths.\n\n---\n\n## Conclusion\n\nThis exploration shows that while backpropagation remains the best tool for neural network weight tuning, Randomized Optimization shines for rugged, non-differentiable problems ‚Äî as long as you pick the right algorithm and tune it carefully.\n\n## Optimization Problems Summary\n\n| Problem | Algorithm (parameters) | Converged Fitness Score | Iterations to Convergence | Function Evaluations to Convergence | Elapsed Time at 1000 Iterations |\n|---------|------------------------|-------------------------|---------------------------|-------------------------------------|---------------------------------|\n| **Continuous Peaks N=100** | **Simulated Annealing (0.55)** | **100** | **5,500** | **5,000** | **0.002047** |\n| | Genetic Algorithm (100 30 30) | **100** | 8,500 | 500,000 | 0.187553933 |\n| | MIMIC (100 0.5) | **100** | 7,500 | 1,000,000 | 6.268513083 |\n| **Flip Flop N=1000** | **Simulated Annealing (0.55)** | **900** | **10,000** | **10,000** | **0.022018** |\n| | Genetic Algorithm (100 30 30) | 580 | 1,500 | 570 | 1.772045639 |\n| | MIMIC (100 0.5) | 800 | 8,000 | 1,000,000 | 254.5714739 |\n| **Traveling Salesman N=100** | **Simulated Annealing (0.55)** | **0.08** | **43,000** | **50,000** | **0.002047** |\n| | **Genetic Algorithm (100 30 30)** | **0.1** | **1,000** | **15,000** | **0.187553933** |\n| | MIMIC (100 50 0.5) | 0.022 | 100 | 6,500 | 254.5714739 |\n\nNo single method dominates all tasks:\n\n- **MIMIC** can capture structure but is computationally heavy.\n- **GA** balances exploration and diversity but can be volatile.\n- **SA** is reliable if well-tuned.\n- **RHC** is simple and effective but easily stuck.\n\nFuture improvements could include a more exhaustive hyperparameter grid search, trying hybrid methods that blend gradient descent and RO, or applying these techniques to larger, real-world problems.\n\n---\n\n## References\n\n- [Random Optimization (Wikipedia)](https://en.wikipedia.org/wiki/Random_optimization)\n- [Genetic Algorithms (Wikipedia)](https://en.wikipedia.org/wiki/Genetic_algorithm)\n- [ABAGAIL Machine Learning Library](https://github.com/pushkar/ABAGAIL)"
    },
    {
      "title": "Machine Learning Part 1: Supervised Learning and Neural Networks",
      "slug": "ml-part-1-supervised",
      "date": "2019-06",
      "description": "A survey of machine learning topics including supervised, unsupervised, clustering and dimensionality reduction, and reinforcement learning",
      "tags": [
        "python",
        "sklearn",
        "machine learning",
        "omscs"
      ],
      "content": "## üìö Machine Learning Series\n\n1Ô∏è‚É£ **Part 1: Supervised Learning & Neural Networks**\n\n2Ô∏è‚É£ [Part 2: Randomized Optimization](/projects/ml-part-2-randomized-optimization)\n\n3Ô∏è‚É£ [Part 3: Unsupervised Learning & Dimensionality Reduction](/projects/ml-part-3-unsupervised)\n\n4Ô∏è‚É£ (Coming soon)\n\nIn the primary Machine Learning course, we explored various algorithms via experimental analysis on two datasets ‚Äî `white wine` and `abalone`. Below is an overview of my analysis on supervised learning algorithms.\n\n## Choosing Datasets\n\nThe popular [wine quality score dataset](https://archive.ics.uci.edu/ml/datasets/wine) I chose is based on a chemical analysis of wines grown in Italy ‚Äî and the resulting user \"quality\" scores ‚Äî scored from 0 to 10. Key attributes of the wine dataset include the amounts of:\n\n> alcohol, malic acid, magnesium, phenols, and flavonoids.\n\nThe idea of choosing a dataset like this is that it's a simple classification problem that's well-suited for determining if chemical constituents of wine can predict quality scores. The wine industry is worth billions in California alone, and if wine producers can find out what chemical constituents produce higher quality wines (at least in the minds of customers), then they likely will.\n\nThe other dataset I used was a modified version of the [abalone age](https://archive.ics.uci.edu/ml/datasets/abalone) dataset ‚Äî the idea being to predict the age of an abalone based on physical measurements such as:\n\n> length, diameter, shucked weight, and gender.\n\nThe actual age of the animal is determined by counting the numbers of rings ‚Äî however, this is a time-consuming process that requires a microscope. Therefore, the goal of this dataset is to see if there's a better proxy attribute to use to count rings.\n\n## Algorithm Analysis\n\nThe code itself is basically searching all possible `hyperparameters` of each algorithm to find optimal results. I used `sklearn`'s `GridSearchCV` function, which searches over a specified range of hyperparameters, finding the optimal hyperparameter combination. The code splits the data into a 70/30 train/test split, normalizes it to a standard scale, performs 5-fold cross-validation on the 70% training data for each hyperparameter combination, and finally calculates the average cross-validation score among the 5 folds. The best 5-fold cross-validation score from our grid search lets us know what the optimal hyperparameters are.\n\nWith the optimal hyperparameters, I can use these settings on the 30% held-out test set for each different supervised algorithm and determine which algorithm would perform the best for solving the central idea of each dataset (predicting quality or predicting age).\n\n## Supervised\n\nIn the supervised assignment, I looked at K-Nearest Neighbors, Decision Trees, Artificial Neural Networks, Boosting, and Support Vector Machines.\n\n### K-Nearest Neighbors (KNN)\n\nKNN is a simple instance-based algorithm that simply looks at the `k` nearest points in feature space. For classification, this is simply a vote or choosing the mode of the neighbors' classes, whereas in a regression setting this would be the weighted mean. Some of the hyperparameters chosen for KNN include `k`, distance functions (Manhattan, Euclidean, and Chebyshev), and whether we weight each neighbor equally or by its distance to the point.\n\nAs seen in one of the convergence curves where the train and test were plotted against our value of `k`, we can see the **bias-variance tradeoff** at work. For low `k` values, we have a **high variance** situation with a highly complex model that only really works for training data ‚Äî the model is not \"general\" enough. An intuitive way to think about this is if we have an outlier \"good\" wine classification in a normally \"bad\" wine region of space, if we have k=1, points around that outlier may be labeled incorrectly.\n\nAs we increase the value of `k`, it can be thought of as smoothing out the decision surface ‚Äî which will decrease variance and increase bias. Increasing `k` too far leads to the opposite scenario ‚Äî a **high bias** situation. It's all about finding the right balance point.\n\n### Decision Trees\n\nIn contrast to KNN, a decision tree is an eager learner as it builds the model on the training data first. Decision trees ask yes or no questions on features to determine which direction to branch. The final leaf node contains the prediction class. Decision trees work well with good splits of the data. In order to measure the quality of splits, I ran Entropy and Gini Index in the hyperparameter grid search. Some decision tree algorithms only look one move ahead to determine the current root of the tree ‚Äî this is generally okay but usually not the most optimal. You usually want good splits at the top, which leads to shorter trees.\n\nIn some of the max depth experiments run, increasing the max depth leads to overfitting. If the tree is allowed too many nodes, it starts to exactly fit the training data ‚Äî therefore it generalizes poorly for test data. Pruning or trimming nodes can help alleviate some of these overfitting issues. Error reduction pruning will attempt to remove the subtree at nodes, make them leaf and re-assign a class. If the resulting tree performs at least as well, that prune is kept. In both datasets, pruning boosted scores from about 75% to 80%.\n\n### Artificial Neural Networks (ANN)\n\nArtificial Neural Networks are learning algorithms modeled after brain neurons. The most basic unit is a `perceptron` that takes a weighted sum of inputs ‚Äî if the sum is greater than some threshold (defined by the `activation function`), then that output is considered on or activated. ANN can tune the weight vectors (for each node connection) at each layer of the network by iteratively nudging them in small steps. The `perceptron training rule` will guarantee convergence (appropriate score/error) in a finite number of iterations if the data is linearly separable. Data that's not linearly separable will use the `backpropagation` rule and gradient descent to iteratively step down the gradient of the cost function. Issues can still occur, such as slow convergence or getting stuck in local minima.\n\nIn my experiments, I used `sklearn`'s `MLPClassifier`, which uses stochastic gradient descent ‚Äî this looks at each training example individually to update weights, offering slightly better runtime than the alternative batch gradient descent.\n\nSome of the experiments here included comparing some of the activation functions (logistic, relu, tanh, identity), comparing varying network dimensions (5, 10, 20 in the first layer versus 5, 10, or 20 in the second layer). Overall, ANN needs the fewest number of training examples of all the supervised algorithms to converge.\n\n### Boosting\n\nBoosting is an **ensemble** method of learning ‚Äî the idea being combining many simple learners leads to a complex system that improves performance. In a common boosting algorithm like `AdaBoost`, each individual learner gets a weighted (depending on its error rate) vote towards the final hypothesis. In addition, each training example is given a variable weight. If the example is modeled poorly in previous learners, its weight increases; if it's modeled correctly, it decreases. Therefore, even with weak learners, we are always gaining information with learners. In general, boosting will reduce the bias (model complexity) in a model that's too general, whereas a related but different method, `bagging`, will reduce variance of a model that is too complex. Boosting can occasionally cause overfitting in a rare case where the first learner perfectly fits the training data, causing weights to never be updated.\n\nThe experiments run on AdaBoost included varying number of estimators, varying learning rate, and comparing learning rate vs the number of estimators in 3D contour plots. AdaBoost has a default learning rate of 1 ‚Äî however, this will slow down the adaptation of the model to training data. A max Abalone score around 30 estimators and a learning rate of 0.04 indicates that estimators have an equal voting power.\n\n### Support Vector Machines (SVM)\n\nSupport vector machines attempt to draw an optimal boundary that maximizes the margin width between different classes. Gutter lines define the max margin and go through points closest to the boundary. While ANN tries to reduce the error cost function, an SVM tries to maximize the margin while still classifying properly.\n\nUsing `sklearn`'s support vector classifier, I plotted various hyperparameters including `gamma` (complexity of decision boundary), `C` (another parameter for decision boundary complexity), and several `kernel functions` (linear, rbf, poly).\n\nOne of the plots includes comparing `gamma` vs `C` on a contour plot with scores. Generally, a high gamma (like a low `k` in KNN) gives closer points more influence and creates a more complicated decision boundary. `C` acts similarly ‚Äî a large value of `C` indicates a more complicated decision boundary. Often times the contour plots perfectly met intuition or expectations, but when I started plotting contour plots, it's sometimes tricky for them to exactly match expectations. That's true for the contour plot below ‚Äî in general, the high value of these hyperparameters represents overfit areas, while the opposite corner represents underfit.\n\n### Comparison and Conclusion of Supervised Algorithms\n\nNo final comparison is complete without consideration of both test performance and runtimes. Boosting was the clear winner and outperforms all other algorithms for both datasets. The only issue is if you look at time, AdaBoost performs the worst. KNN and Decision Trees run the fastest.\n\nA key takeaway is the **no free lunch theorem**, which states that an algorithm effective for one problem may not be suitable for others. Each algorithm includes its own inductive biases and complexities. The only way to find the right tool for the job is to find the optimal hyperparameters and plot the performance ‚Äî in addition to considering runtime performance.\n\n## Comparison Table\n\n| | Inductive Bias | Pros | Cons | Good at |\n| ------------------------------ | ---------------------------------------------------------------- | -------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------ | ----------------------------------------------- |\n| **KNN** | Classes are similar to nearest points | Intuitive; Fast runtime; Less prone to overfitting; Limited parameter tuning | Hard to model complex data; Lazy learner is slow to predict new instances; Poor on high dimensional datasets | Low-dimensional datasets |\n| **Decision Trees** | Shorter trees preferred; High information gain splits at the top | Fast runtime; Robust to noise/missing values; Visually intuitive; Fast training & prediction | Possible duplication within tree; Complex trees can overfit and be hard to interpret | Medical diagnosis; Credit risk analysis |\n| **Artificial Neural Networks** | Smooth interpolation; Bias towards minima via gradient descent | Can model complex relationships; Can separate signal from noise | Can overfit; Long training times; Black box; Many parameters | High dimensional datasets like images |\n| **Boosting (AdaBoost)** | Ensembles reduce bias of individual learners | Flexible; Proven effective; Increases margin; Reduces overfitting | Weak classifiers too complex can overfit; Vulnerable to noise; Slow training | Problems with individual model instability |\n| **Support Vector Machines** | Classes separated by wide margins | Can model complex relationships; Maximizing margins makes it robust to noise | Non-intuitive parameters; Long runtime; Not great for large or imbalanced datasets | Complex domains with clear margin or separation |\n\n> Future ML algorithm discussion coming..."
    },
    {
      "title": "SenseCourse",
      "slug": "sensecourse",
      "date": "2018-10",
      "description": "A look at using Watson AI to select courses based on your personality",
      "tags": [
        "flask",
        "python",
        "javascript",
        "omscs",
        "edtech"
      ],
      "content": "## Intro\n\nSenseCourse is an application that a student teammate and I built for the [Education Technology](https://omscs.gatech.edu/cs-6460-educational-technology) class in my master's program (OMSCS). The Education Technology course offered a comprehensive examination of the intersection between education and technology, focusing on pedagogical models, current issues in EdTech, and insights from research papers and past projects. The application was built using Flask and jQuery and hosted on Heroku.\n\n#### Choosing SenseCourse\n\nWhile going through several EdTech research papers, I was intrigued by the topic of sentiment analysis and opinion mining and how it could help provide insights into the learning process. A few papers illustrated how well machine learning techniques worked to offer feedback to professors (or students) based on writing samples. The research papers noted how professors could use this automated feedback to adjust their teaching style to match student learning styles.\n\nThis ultimately led to us developing SenseCourse‚Äîan application that helped students choose a particular set of OMSCS classes (specialization). Fortunately, the OMSCS program had collected hundreds of reviews for each course from former students. As a credit to the program, many of the reviews were positive, but they also had a lot of unrealized feedback potential that we noticed.\n\nThe idea was to generate a collective sentiment analysis for each course based on these reviews and match them with the sentiment analysis generated by user-submitted writing samples. The SenseCourse app asks users several open-ended questions about themselves in the hopes that users respond with enough text so that IBM Watson can provide meaningful insights about their personality.\n\n## IBM Watson\n\nIBM Watson is a natural language processing service for text analytics. A subset of the service includes Personality Insights, including what they now call Entity Emotion Scores. While the API has changed since we developed our app, key classification scores are still output today for emotions like joy, anger, fear, and sadness. You can view a short demo of the [text analysis tool here](https://www.ibm.com/demos/live/natural-language-understanding/self-service/home). In the SenseCourse live demo, the application is not hooked up to the now-modified API, but it does have a demo of what the output result looked like when it was working and turned in for the end of the course.\n\n## Future Research\n\nConsidering the one-month project timeline and our subsequent coursework, a full controlled study was beyond this EdTech course's scope. This study might have had one group of students who took the courses recommended by SenseCourse and another who chose classes on their own. By comparing these two control groups and how successful the students were in each class, we might understand how effective the sentiment analysis and course matching schemes were.\n\nAnother possible avenue of research in this area would be to see what kind of feedback we could provide to professors from the course reviews. Given the sheer volume of reviews available, perhaps there was some hidden meaning and feedback available in all the reviews for a particular course. If any of that feedback could allow a professor to modify their teaching style, I believe that would be an interesting experiment. Given that this project was only meant to be completed in about a month and we both had to move on to other classes, a full controlled study was beyond the scope of this EdTech course.\n\n## Conclusion\n\nI believe this project has the potential for further refinement by larger EdTech companies with big data resources, such as Coursera, Udemy, or Udacity. As mentioned, there are also several possible research studies that could be realized. For us, it was an interesting foray into the world of text and sentiment analysis and ultimately helped me choose my final two courses."
    },
    {
      "title": "GitHub Browser",
      "slug": "github-browser",
      "date": "2017-06",
      "description": "Dashboard to visualize GitHub repositories, code languages used, and connections to other repos.",
      "tags": [
        "angular",
        "javascript",
        "d3"
      ],
      "content": "The GitHub browser is a simple single page app built in Angular that lets users search and visualize a breakdown of repositories for a given user. The idea was to explore developing single page apps in combination with a data-rich API like GitHub. The utility of creating a browser stems from the fact that repositories typically have multiple contributors, making navigation through different users' repositories straightforward to implement. This project used only a portion of the GitHub API data, and it still had a fair amount of data to visualize.\n\nAs shown above, the actual API call is done on a lightweight Express server deployed to Heroku that proxies our requests from the client to the GitHub API. This intermediate server also allows us to safely store and use the OAuth App client ID and secret credentials.\n\n## GitHub API Request Limit\n\nAPI requests can be made directly from the browser to GitHub without encountering any Cross-Origin Resource Sharing (CORS) issues (the GitHub API returns `access-control-allow-origin: *`). The problem is both that there is an API call limit and that we can't store the OAuth credentials on the client ‚Äî the only safe calls from the client would have to be unauthenticated ‚Äî which would only let us view a couple of users or repos before hitting the limit (each route has multiple API calls). The [unauthenticated limit is 60 calls per hour](https://docs.github.com/en/rest/overview/resources-in-the-rest-api#:~:text=For%20unauthenticated%20requests%2C%20the%20rate,has%20custom%20rate%20limit%20rules.&text=The%20maximum%20number%20of%20requests,permitted%20to%20make%20per%20hour.). We can actually see that limit shown in a returned HTTP header `X-RateLimit-Limit` and `X-RateLimit-Remaining`. Meanwhile the authenticated limit is 5,000 ‚Äî plenty sufficient for a small project like this.\n\nPassing just the clientID and clientSecret from the lightweight Express server to the GitHub API doesn't technically \"authenticate\" the calls ‚Äî it simply identifies what OAuth application is being represented ‚Äî which in turn increases our API rate limit. However, the docs indicate this is ok in server-to-server scenarios like this.\n\n## The Browser\n\nThe browser simply lets you:\n\n1. Search for a user's repo\n2. View the code language breakdown for a given user's repo\n3. View individual repo contributors and identify who the top contributors by file additions and deletions are\n\nGiven more time, I plan to refine the styling, potentially upgrading to Emotion or Styled Components. I'd also like to implement a proper client OAuth login authorization and access token flow ‚Äî possibly in another post. Using this we might be able to have another route viewing data about the user's own repos, including private ones.\n\nIn addition there's plenty more GitHub API data ‚Äî as can be seen from the hypermedia HATEOAS resource links that we get with high-level API requests to users and repos for example."
    }
  ],
  "books": [
    {
      "title": "Accelerate: The Science of Lean Software and DevOps Review",
      "slug": "accelerate",
      "date": "2025-06",
      "description": "A practical, evidence-backed review of the definitive DevOps and software delivery performance book.",
      "tags": [
        "engineering",
        "devops"
      ],
      "content": "## Introduction\n\n**Accelerate**, by Nicole Forsgren, Jez Humble, and Gene Kim, distills years of DevOps research into clear, actionable insights. It makes the case that software delivery performance drives business success ‚Äî and that speed and stability reinforce each other rather than compete.\n\n> \"High-performing technology organizations are not just fast ‚Äî they are also stable and reliable.\"\n\n## Core Idea: Speed and Stability Go Hand-in-Hand\n\nA major takeaway is that there is no tradeoff between moving fast and maintaining system reliability. The same practices that increase delivery throughput also reduce failure rates and recovery times.\n\n---\n\n## Focus on Capabilities, Not Maturity\n\n**Accelerate** strongly recommends moving away from maturity models, which suggest a static \"end state,\" and instead investing in **capability models** that foster continuous improvement.\n\n| Capability Models | Maturity Models |\n| ----------------------------------- | --------------------------------------- |\n| ‚úÖ Flexible and outcome-focused | ‚ùå Static levels imply \"done\" |\n| ‚úÖ Customizable per team | ‚ùå One-size-fits-all tooling |\n| ‚úÖ Ties skills and tech to outcomes | ‚ùå Often disconnected from real results |\n\n---\n\n## The Four Key Metrics\n\nThe authors validated four universal metrics that reliably predict software delivery and operational performance:\n\n1. **Lead Time for Changes** ‚Äî How quickly code changes reach production.\n2. **Deployment Frequency** ‚Äî How often the team deploys working code.\n3. **Mean Time to Restore (MTTR)** ‚Äî How fast the team recovers from incidents.\n4. **Change Failure Rate** ‚Äî Percentage of changes that result in degraded service.\n\n**Throughput:** Lead Time + Deployment Frequency \n**Stability:** MTTR + Change Failure Rate\n\nElite teams deploy on-demand, restore failures in under an hour, and keep change failures under 15%.\n\n---\n\n## Technical Practices\n\nKey engineering approaches that support high performance:\n\n- **Continuous Delivery (CD)** ‚Äî Automate build, test, deploy pipelines.\n- **Trunk-Based Development** ‚Äî Use short-lived branches and merge frequently.\n- **Feature Flags** ‚Äî Decouple deployment from feature release.\n- **Loose Coupling** ‚Äî Architect services to be independently testable and deployable.\n- **Shift Left on Security** ‚Äî Embed security throughout development, not just at the end.\n\n---\n\n## Lean Management\n\nLean principles drive better software delivery:\n\n- **Limit Work in Progress (WIP)** ‚Äî Prevent overload and reduce lead times.\n- **Visual Management** ‚Äî Use boards and dashboards to show work status and outcomes.\n- **Feedback from Production** ‚Äî Use runtime data to guide daily decisions.\n- **Lightweight Change Approvals** ‚Äî Automate checks and peer reviews instead of relying on Change Advisory Boards (CABs).\n\n> \"External approvals slow you down and do not improve stability.\"\n\n---\n\n## Culture: The Hidden Engine\n\nThe book heavily cites Westrum‚Äôs cultural model: Generative (high-trust, learning-focused) cultures outperform bureaucratic or fear-driven ones.\n\nSigns of a healthy culture include:\n\n- Open, timely information flow.\n- Shared risk and shared credit.\n- Blameless postmortems.\n- Messengers rewarded, not shot.\n\n> \"Where there is fear, you do not get honest figures.\" ‚Äî W. Edwards Deming\n\n---\n\n## Leadership\n\nHigh-performing organizations rely on **transformational leaders** who:\n\n- Share a clear, inspiring **vision**.\n- Communicate honestly, even under uncertainty.\n- Support intellectual challenge and growth.\n- Recognize and reward good work.\n- Foster alignment and psychological safety.\n\nLeaders should change **behaviors first** to shift culture ‚Äî not the other way around.\n\n---\n\n## Employee Wellbeing\n\n**Accelerate** addresses burnout and deployment pain: \nHigh deployment pain, excessive manual steps, and rigid processes drain teams. Automate repetitive tasks, keep feedback loops tight, and make deployments boring.\n\nKeeping core software delivery in-house rather than outsourcing protects strategic advantage and supports a resilient, high-trust culture.\n\n---\n\n## Key Takeaway\n\n**Accelerate** proves through data that you don‚Äôt have to choose between moving fast and staying safe. With the right technical practices, lean principles, and generative culture, you can have both.\n\n> \"Software delivery performance is not a cost center ‚Äî it is a key competitive advantage.\"\n\n---"
    },
    {
      "title": "Staff Engineer",
      "slug": "staffengineer",
      "date": "2023-11",
      "description": "An exploration of the pivotal role of a Staff Engineer in technology companies",
      "tags": [
        "management",
        "engineering"
      ],
      "content": "## Intro\n\nSoftware engineers usually reach the Senior level within 5-8 years in the tech industry. At this stage, further promotions are not mandatory and are more of an exception than an expectation. At this point, engineers often have the option to transition into engineering management ([see Manager's Path](/books/managerspath)).\n\nHowever, for those who wish to advance their careers without shifting to engineering management, many companies offer a two-track career path. The first track is engineering management, while the second is technical leadership, with roles like Staff Engineer and Principal Engineer.\n\n_Career tracks splitting into staff-plus leadership vs engineering management_\n\n---\n\nThe book identifies four distinct staff-plus engineer archetypes across companies:\n\n| Archetype | Description | Primary Responsibilities | Operating Environment | Common in Company Size/Type | Key Skills or Traits |\n| ---------- | ----------------------------------------------------------- | ------------------------------------------------------ | -------------------------------------------- | ------------------------------------------------- | ---------------------------------------------- |\n| Tech Lead | Leads a team or cluster of teams in approach and execution. | Scoping tasks, team coordination, technical vision. | Agile, team-centric companies. | Varies, often in medium to large companies. | Project management, technical expertise. |\n| Architect | Responsible for a specific technical domain. | System design, business and user need understanding. | Companies with complex or coupled codebases. | Large companies, those addressing technical debt. | In-depth technical knowledge, foresight. |\n| Solver | Tackles complex, critical problems. | Problem-solving, working on organizational priorities. | Individual-centric planning companies. | Large, mature companies with technical debt. | Problem-solving, adaptability. |\n| Right Hand | Operates akin to a senior leader without managerial duties. | Strategic problem resolution, delegation. | Senior leadership environments. | Very large organizations. | Strategic thinking, alignment with leadership. |\n\nIn order to understand which role is right for you - you have to stay engaged and know what kind of work energizes you. A tech lead or architect might work with the same people or problems for years, developing a tight sense of team and shared purpose. A solver or right hand type might bounce from fire to fire, only having transactional interactions with folks they're working with each week.\n\n## What do Staff Engineers actually do\n\n> \"The role of a Staff-plus engineer depends a lot on what the team needs and also what the particular engineer's strengths are. ... usually their main focus is working on projects/efforts that have strategic value for the company while driving technical design and up-leveling their team.\" - Diana Pojar\n\nThere's a set of tasks that all archetypes will participate in - setting/editing technical direction, providing sponsorship and mentorship, injecting engineering context into org decisions, and being glue:\n\n- **Setting Technical Direction**:\n\n - Serve as a part-time product manager with a focus on technology.\n - Prioritize the real technological needs of the organization over personal interests in specific technologies.\n\n- **Mentorship and Sponsorship**:\n\n - Influence the company's long-term growth by nurturing other engineers.\n - Engage more in sponsorship than mentorship to maximize influence and support.\n\n- **Providing Engineering Perspective**:\n\n - Offer valuable insights during critical, time-sensitive decision-making processes.\n - Ensure that an engineering viewpoint is considered in important organizational decisions.\n\n- **Exploration**:\n\n - Handle ambiguous, significant issues that fall outside the company's current systems.\n - Build organizational trust to be tasked with exploration, accepting the risks of potential failure.\n\n- **Being Glue** (see Tanya Reilly's Being Glue):\n\n - Undertake essential yet often unnoticed tasks to maintain team momentum and successful project delivery.\n - Recognize the shift from frequent coding to facilitating broader project goals and team needs.\n - This is an expected task when you're senior, but doing it too early can push people out of engineering\n\n- **Coding and Contributions**:\n\n - Expect reduced time spent on direct software development compared to earlier career stages.\n - Recognize frequent coding as a comfort zone indicator and a sign of potentially misplaced focus.\n\n- **Pace and Feedback**:\n - Adapt to a slower feedback loop that extends over weeks, months, or even years, rather than immediate results.\n\n## Does the title even matter\n\nIf you're a senior engineer is it even worth it to invest time to become a staff engineer? Pursuing a staff-plus role offers several advantages::\n\n- **Informal gauges of seniority** - Don't need to prove yourself as much, allowing you to focus on the core work\n- **Being in the room** - able to provide input before implementation (when it's cheap to do so)\n- **Compensation** - different than a senior engineer\n- **Access to interesting work** - While the role can sometimes grant access to interesting work, a staff engineer can't just pursue interesting work out of personal interest as they should put the team or business first\n\n## Working on what matters\n\nAs individuals progress in their careers, the challenge becomes navigating the increasing expectations against the backdrop of a fulfilling life filled with family, hobbies, and personal growth. The essence of sustaining a long and successful career lies in pacing oneself, ensuring that as responsibilities grow, one doesn't sacrifice personal well-being for professional achievements. It's about consciously avoiding the pitfalls of busyness over productivity, vanity metrics over substance, and unattainable goals over realistic ones, focusing instead on work that truly matters both personally and to the organization.\n\n_Splitting technical staff-plus leadership and engineering management_\n\n---\n\nThere are also a few ways to get tripped up when looking to prioritize what to work on:\n\n| **Archetype** | **Description** | **How to Avoid** |\n| ------------------ | ---------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------- |\n| **Snacking** | Engaging in tasks that are easy and low-impact, offering a false sense of accomplishment. | Regularly evaluate the impact of your tasks and focus on those that align with organizational priorities. |\n| **Preening** | Performing low-impact, high-visibility work, which can be misconstrued as impactful due to its visibility. | Seek out work that not only has visibility but also significantly contributes to the company's goals. |\n| **Chasing Ghosts** | Pursuing high-effort, low-impact projects that may stem from a misunderstanding of company challenges. | Invest time in understanding the company's core challenges and resist the urge to initiate changes without thorough analysis. |\n\n## Writing Engineering Strategy\n\n> \"I kind of think writing about engineering strategy is hard because good strategy is pretty boring, and it‚Äôs kind of boring to write about. Also I think when people hear ‚Äústrategy‚Äù they think ‚Äúinnovation‚Äù \" - Camille Fournier\n\nYour company may call them RFCs or tech specs, but a good design doc describes a specific problem, surveys possible solutions, and explains the selected approach's details. Design docs should be grounded in specifics to prevent multiple different interpretations by engineers.\n\nWriting an effective engineering strategy involves creating mundane yet essential documents that guide decision-making and align teams. The process of developing a strategy is straightforward and more effective than many realize. The book offers a few recommendations:\n\n- **Identify and Clarify the Problem** - Begin with a clear statement of the problem, as it sets the stage for finding effective solutions. If solutions aren't clear, spend more time refining your understanding of the problem. When stuck, consult with others for fresh perspectives.\n- **Simplify the Design Document Template** - Utilize the existing design document template of your company as a foundation. Avoid making the template overly complex, as this can deter people from writing design documents. Aim for a minimal template that highlights the most crucial sections, particularly for projects with significant risks.\n- **Collaborative Input, Individual Writing** - Acknowledge that having all the relevant information to write the best design document is unlikely. Seek input from various stakeholders early in the process, but be cautious about turning this collaboration into a group writing effort. While it's important to incorporate a wide range of views, the actual writing should be a solo endeavor to ensure clarity.\n- **Aim for Quality, Not Perfection** - Focus on writing a good and substantial document rather than waiting to achieve perfection. When providing feedback on others' designs, avoid the expectation that their work should match your highest standards. Especially in senior roles, encourage the production of quality work, rather than insisting on perfection in every design.\n\n### Synthesize the design docs into a strategy\n\nAfter gathering five design docs, look for controversial decisions that came up in multiple designs (particularly those that were hard to agree on). An example from the book is deciding whether Redis is just a cache or if it's appropriate to use as durable storage. The idea is to reflect on how these decisions were made and wrote them down as a strategy.\n\n- **Analyze and Synthesize Design Documents** - Review the five design documents collectively. Identify and focus on controversial or difficult decisions that recur in multiple documents. Use these insights to form a cohesive strategy.\n- **Guide Tradeoffs with Clear Rationale** - Effective strategies should guide decision-making tradeoffs and clearly explain the underlying rationale. Avoid strategies that state policies without context, as they quickly become irrelevant and difficult to adapt.\n- **Be Specific and Opinionated** - Emphasize specifics in your strategy, avoiding generalizations. Strategies should be opinionated, providing clear guidance on decision-making, and must demonstrate the thought process behind these opinions.\n- **Show Your Work** - Like solving a math problem, showing your work in strategy development is crucial. This approach not only builds confidence in the strategy but also allows others to understand and adapt it as contexts change.\n\n### Combining Strategies into a Vision\n\nCreating a compelling engineering vision from multiple strategies involves weaving together different approaches into a cohesive plan for the next two to three years. The final version should give you what Tanya Reilly calls [\"a robust belief in the future](https://leaddev.com/technical-direction-strategy/sending-gifts-future-you) - the result should be a common thread among existing strategies as well as making it easier to write additional strategies that stand the test of time. Here's a few tips for writing a vision:\n\n- **Combine Strategies Thoughtfully** - Analyze and harmonize different strategies, even if they seem contradictory.\n- **Focus on a 2-3 Year Horizon** - Develop a vision that is realistic for a rapidly changing technological and business landscape.\n- **Align with Business and User Needs** - Ensure the vision serves users and aligns with leadership's core values. (Ineffective visions may overemphasize technical complexity without clear benefits to customers or alignment with leadership values. For example, a vision that proposes using the latest AI technology because it's innovative, without showing how it drives business growth)\n- **Be Ambitious but Realistic** - Aim for the best possible outcomes within resource constraints. (You're not writing a vision with the assumption of infinite resources)\n- **Detail Matters** - Provide concrete details and avoid vague statements to guide strategy effectively.\n- **Keep It Concise** - Limit the vision to 1-2 pages and link to more in-depth documents for interested readers. (Most people won't read longer than a page)\n- **Share and Refine** - Share across the organization and measure success by the improvement in strategies and design documents over time.\n\n## Managing Technical Quality\n\nOne of the roles of engineering leadership is to maintain appropriate technical quality, while still devoting as much energy as possible to the core business. It's easy to point fingers when technical quality is low, but this scenario is not a crisis - it's expected. Some tips the books recommends:\n\n- **Start with the lightest weight solutions first** - only progress toward massive solutions as earlier efforts fail to scale. Quick fixes provide valuable learning experiences. Celebrate the removal of ineffective practices along the way.\n\n- **Adopt a performance engineer mindset to identify hotspots** - When facing quality issues, it's tempting to pinpoint and rectify process failures (i.e, we had a deployment cause an outage because a code author didn't correctly follow a code test process, so let's require tests with every commit). It's more important to identify the actual problem and hand than to implement fixes via process-driven accountability. Teams should adopt a `performance engineer's mindset` whereby they measure the system, identifying where the bulk of issues lie so you can focus on just that area. - Sometimes it's also better to just discard an issue rather than try to fix it\n\n- **Align technical decisions with shared visions** - ensure you avoid centralizing decisions with one architect, and instead, use tools, onboarding and organizationl design to foster alignment\n\n- **Gradual best practice implementation** - Successful adoption of best practices, like Scrum, requires a gradual approach, starting with small tests and evolving based on feedback. It's important to focus on one practice at a time, ensuring each is well-established before introducing new practices, and to base the adoption on solid research and readiness.\n\n- **Targeting leverage points** - identifying hotspots works well for issues you already have, but there are a small subset of areas where extra investments preserves quality over time (`\"leverage points`). Areas of concentration should be interfaces (mediators between different parts of software that hide complexity), stateful systems (an area that gets complex faster than any other area), and data models (at the intersection of stateful systems and interfaces, and should be designed to be rigid yet still flexible to changes over time)\n\n- **Aligning technical efforts with org vision** - all technical decisions should support a unified vision (like vectors pointing in the same direction). To prevent misalignment, the book recommends several strategies including direct feedback, training and feedback, leverage Conway's Law where orgs create systems that reflect their structure, and developing engineering strategy based on tech specs that also reflect the broader org strategy/vision.\n\n### Measuring and Enhancing Technical Quality\n\nAccurate measurement of technical quality in software engineering is key. It's crucial to have a good definition of quality - and then to have the instrumentation to create a quality score that you can track over time.\n\nSome technical quality definitions might include:\n\n- `What percentage of the code is statically types?`\n- `What percentage of files use the preferred HTTP library?`\n- `Do endpoints respond to requests within 500ms after a cold start?`\n- `How many functions have dangerous read-after-write behavior?`\n\n#### Technical Quality Team\n\nEstablishing a technical quality team (sometimes called Developer Productivity, Developer Tools, or Product Infrastructure) dedicated to improving and preserving software quality across the company is crucial. This team should focus on measurable impacts, user-centric tool design, and prioritizing high-impact projects.\n\nSome tips for the success of quality teams:\n\n- trust metrics over intuition\n- adoption/usability of your tools are much more important than raw power - so do user research on your tools and listen to/learn from your users\n- do fewer things, but do them better\n- avoid having the quality team impose a globally optimal or one-size-fits-all approach for all teams (i.e, some teams have atypical workloads - think developers using a Javascript backend, which doesn't mesh well with a Machine Learning team that wants everything to be in Python). Understand each team's unique requirements and find a healthy balance between standardization and accommodating diverse needs\n\n## Staying Aligned with Authority\n\nTo be effective within a staff-plus role, you'll need to retain some level of organizational authority, which depends on remaining deeply aligned with a bestowing sponsor - generally your direct manager. Typically, the support system that got you to a staff role will fade away when you're there, so you must align the pieces around you for your own success.\n\nThe book highlights several tips for strategic alignment:\n\n- **Communication is key** - try to prevent both you surprising your manager and your manager/sponsor surprising you through frequent and open lines of communication.\n- **Feedback and adaptation** - regular feedback and a willingness to adapt are important\n\n - **Proactively solve problems by signaling to your manager** - To prevent your manager from getting surprised by the organizations, considering feeding them additional context of problems you're noticing\n\n- **Aligning vision with leadership to influence effectively** - You should develop your own perspective on how the world should work (this sharpens your judgement and proactive capabilities). However, make sure to align your vision with that of senior org leaders, while still maintaining some sense of your own ideas in a non-confrontational way - this will let you influence without friction.\n\n### Lead by following\n\nManagement is a profession, but leadership is a trait one can demonstrate within any profession. The most effective leaders spend more time following than they do leading:\n\n- They give support quickly to others who are working to make improvements\n- They make feedback explicitly non-blocking if there will be disagreements (share perspective rather than suggesting people change their approach)\n- They integrate their worldview with their team's, thereby accelerating progress\n- **They define the gap between how things are and how they ought to be, and identify proactive solutions to narrow the gap. They also care enough about the gap to attempt solutions.**\n\n### Agreeing on Decisions\n\n> I present what I think is the best case for us, and people can disagree with that. And, you know, they often do. I‚Äôm steering and influencing more than saying, ‚ÄúI‚Äôve got the authority to just tell you what to do.‚Äù I‚Äôve never seen that style work well. - Keavy McMinn\n\n- Effective meeting strategies -\n - Approach meetings with the intent to understand and align with others, rather than just pushing your own perspective\n - Listen through questions - this involves active listening and asking questions to understand other's viewpoints. **Ask 3 good questions before you share your perspective ** (you'll likely see the room shift)\n - Defining a clear goal/purpose for meetings\n - Read the room to understand when to escalate discussions or break them down into smaller groups\n- Avoid forcing consensus in meetings - identify ways to explore disagreements\n\nOften, engineers are confident their perspective is right, so there are ocassions where getting other folks in the room to agree is sometimes a zero sum game. Instead, think about applying some of the approaches listed above and think about entering a room with the goal of agreeing on a problem at hand.\n\n### Difficult Colleagues\n\nThe above approaches work well for leaders looking to reach agreement with the majority of folks - but you won't agree with everyone. Difficult colleagues will often withold consent from the group or don't really listen. Some possible strategies to handle this include:\n\n- Including folks in a meeting that the difficult colleague can't be rude to (like a VP of Engineering)\n- Aligning with them before the meeting, so they feel heard and are less likely to derail the discussion\n\n### Creating space for others\n\n> At this point, I spend less time advocating for specific technologies or programs and more time empowering others to advocate for the technologies and programs that they think are important. I also try to be a source of knowledge and support that people can reach out to for feedback, especially on cross-cutting product decisions and on presentation of ideas to the rest of the organization. - Michelle Bu\n\nOne indication of a successful staff-plus engineer is that your organization benefits from your contributions, but doesn't rely upon them. Many staff-plus reach the role by becoming the \"go-to\" person for their organization, so it can be difficult to transition from essential to adjacent.\n\n- Create more space for others in discussions:\n\n - When you make a key contribution, reflect on what it would take for someone else to make that contribution next time\n - Shift contribution toward asking questions\n - Think about trying to involve folks who may not be participating\n - Destigmatize low status activities like note-taking\n\n- Help others learn from decisions:\n\n - Record decisions (write them down) so that others can learn\n - Circulate decisions early (and before you've crystallized on a decision)\n - Being able to listen to coworkers and being open enough to change your mind based on different discussions\n\n- Creating space via sponsorship\n - When you get critical work, ask yourself who could grow the most by taking on this work - then have them lead that task/project\n - As a sponsor, you can advise and provide context, but ultimately you should be able to let the person you're sponsoring take an approach that you wouldn't\n\nThe only way to remain a long-term leader of a successful company is to continually create space for others to take recognition and reward.\n\n### Building a Network of Peers\n\nOf the staff-plus engineers interviewed in the book, the most consistent recommendation was to develop a network of peers.\n\n- **Be visible** - Since there is a pent-up demand for community among staff-plus eng, the easiest way to build a network is to be visible (conferences, staff eng slack spaces)\n- **Internal networks** - This is easier at larger companies. When folks leave your org and spread across the industry, it will help bootstrap your broader network\n- **Quality over quantity** - Build your network with folks you trust, respect, and who inspire you. They'll help you solve the most difficult problems that come your way\n\n### Presenting to executives\n\nYour career is constrained by your ability to influence executives effectively. This is a skill on its own, since executives are usually unfamiliar with your domain and have limited time for the topic at hand. Presenting to executives can be challenging if your presentation style does not align with what executives are accustomed to, particularly if it leads to the conversation being derailed. For example, some executives might focus solely on data, discounting any points not directly tied to concrete evidence.\n\nPreparing in advance to align your presentation with styles can help prevent miscommunication and increase the likelihood your ideas will be received positively. When you meet with executives it's typically for planning, status reporting, or resolving misalignment. The key objective is to gain as much insight as possible from the executive, rather than trying to change their mind.\n\n- Structured documents are a key tool to help clarify your thoughts. One such format is SQCA:\n\n - Situation - define relevant context\n - Complication - explain why current situation is problematic\n - Question - state core questions to address\n - Answer - state best answer to posed question\n\n- Mistakes to avoid:\n - Never fight feedback - if you do, others will withhold comments and you'll get less out of it\n - Don't evade responsibility/problems - by putting issues on the table, you can move towards solving together rather than trying to hide things\n - Don't present a question without an answer - doing so may make executives question judgement\n - Don't fixate on a preferred outcome - there could be context you're missing\n\n### Promotion Packets\n\nCreating a promotion packet for a staff-plus role can be a strategic tool for career development. Instead of viewing it as just a requirement for promotion, it can serve as a roadmap for reaching your goals\n\n- Start early - begin working on your staff promotion packet well before you're up for promotion - using it as a guide rather than just a formality\n- Template for packet - include details of your staff projects, organizational improvements you've contributed to, the quantifiable impacts of your projects, mentorship roles, \"glue work\" for the organization, and areas for personal improvement\n- Iterative Process:\n\n - Personal reflection - understand why you want a Staff level position and ensure it aligns with career aspirations\n - Manage expectations - recognize that promotions at this level take time (promotions built over years)\n - Engage your manager - discuss your promotion goals and the packet in your one-on-ones, seeking feedback and guidance\n - Regularly discuss your progress towards meeting the promotion with your manager (addressing any gaps so as to strengthen your case)\n - Write and Revise - initially draft your promotion packet, then review and edit it for clarity/content\n - Get feedback from peers (especially those in staff-plus roles)\n\n- Find a sponsor - promotions are a team activity - don't play team games alone. This should be a person speaking up for your work in forums of influence.Sponsors typically possess considerable organizational capital but limited time, so you must assist in aligning the pieces for them.\n- Make sure your skip-level manager is familiar with your work's impact to remember it in a meeting\n\nThis approach is not just about assembling a packet for promotion; it's about focusing your efforts and aligning with your manager to actively work towards your goal. When it's time to formalize your packet, it will be a refinement of your ongoing work rather than a last-minute compilation, making the promotion process smoother and more reflective of your continuous development.\n\n### Staff Projects\n\n> There isn‚Äôt an explicit expectation, nor is it listed anywhere as a formal requirement, but it is understood that you‚Äôll complete a Staff Project to get promoted. I can‚Äôt think of any Staff promotion that didn‚Äôt include a really strong project, typically a multi-person project where the engineer was the Tech Lead. - Ritu Vincent\n\nMost individuals who attain a staff role do so by either accumulating a solid track record over time, switching roles to attain the title, or completing a `\"staff project\"`. The staff project is usually complex and important enough that the person who copletes it has proven themselves a Staff engineer. Some of the characteristics of a staff project include:\n\n- **Complex/ambiguous** - In contrast to early career (well-defined) problems, the staff project is large, ambiguous, and poorly scoped. Part of the challenge is working through this ambiguity\n- **Numerous and divided stakeholders** - a lack of organizational alignment around the problem and its solution\n- **Highly visible** - talked about at \"All Hands\" type meetings. As a result both failure or success will be visible.\n\nIn order to obtain access to projects of this nature - the book offers a few additional tips that includes:\n\n- Stay highly aligned with leadership team\n- Be known to have technical aptitude for the problem at hand\n- It helps when your company has a pressing need to solve a staff-level problem\n\nRegardless of whether or not you want the staff title - you should still pursue self-growth opportunities that staff projects provide\n\n### Get in the decisioning room, and stay there\n\nGaining access to key decision-making spaces, often referred to as \"the room,\" is a common challenge and aspiration for engineers, especially at the Staff-plus level. Here's a succinct summary of the advice provided:\n\n- **Bring unique value** - have something useful to contribute that isn't already present\n- **Find a sponsor** - secure someone in the room who will advocate for your inclusion. Also make sure to communicate to sponsors that you actually want to be in the room\n- **Volunteer for tasks, even if they're low-status** - i.e, note-taking\n- **Understand the room's purpose** - align with the room's intent and operate within its norms\n- **Be low friction** - you're more likely to be involved if you're known as someone who can navigate difficult conversations effectively\n- **Be consistent** - regular attendance and reliability are crucial\n- **Speak clearly and concisely** - learn to use economy of speech. It's your responsibility to be understood\n\n- Exiting the room:\n - **Evaluate the room's value** - assess whether the room is a beneficial investment of your time\n - **Leave Strategically** - If a room no longer serves your goals, consider exiting and potentially sponsor someone else to take your place\n\n### Being Visible\n\nYour goal is to be known for good things while minimizing org bandwidth you consume to do so. Staff-plus roles are leadership roles - and by giving you such a title, the company is bringing you into its leadership team. In order to bring you into leadership, existing leaders have to know and believe in you.\n\n- **Internal Visibility** - work on things that matter to your leadership and org. A good reputation and visibility within the company are crucial to promotion to staff. Produce and share long lasting documents like architecture docs or tech specs. Lead or participate in company forums and events. Promote your team's work and achievements on Slack/email.\n\n- **Executive Visibility** - It's particularly important to be known and trusted by the company's executives (as they have a say in promotions). Building a relationship with your skip level manager can be valuable here.\n\n- **External Visibility** - This could be a conference talk or a highly publicized blog. While with internal efforts, your competing for attention with your peers, external efforts don't have this same competition.\n\n## Conclusion\n\nThe 'Staff Engineer' book is a personal guide for engineers navigating their journey towards Staff and Staff-plus roles in the tech industry. It's like a mentor in print, providing valuable insights into career progression, leadership, and the art of effective communication. The book not only outlines the paths to success and the essential skills required but also inspires with its focus on the personal significance of visibility, strategic decision-making, and aligning one's values with organizational goals. It's a hopeful beacon for aspiring engineers, encouraging them to balance technical prowess with strategic thinking and interpersonal skills to reach new professional heights."
    },
    {
      "title": "The Manager's Path Review",
      "slug": "managerspath",
      "date": "2023-06",
      "description": "A review of the canonical engineering management book ",
      "tags": [
        "management"
      ],
      "content": "# Introduction\n\nSoftware engineering management is a multifaceted role involving both team leadership and technical decision-making. `The Manager's Path` is the canonical book in this field, guiding readers from the basics of management to the intricacies of executive leadership roles such as VP or CTO.\n\n> \"What engineering managers do, though, is not pure people management. We are managing groups of technical people, and most of us come into the role from a position of hands-on expertise. I wouldn't recommend trying to do it any other way!\"\n\n# Chapter 1: Management 101\n\n> \"Friends of mine talk about their best managers as managing them with 'benign neglect.'\"\n\nEveryone's first management experience is actually being managed. For those interested in management, it's crucial to seek out a competent manager to report to; if that's not possible, observing various management styles is a beneficial alternative.\n\n#### 1-on-1s\n\nOne of the most important aspects of management is establishing a regular cadence of 1-on-1s. These should create a safe and trusting environment that allows for human connection while also providing a platform to discuss the direct report's career aspirations and goals. Managers should listen actively and empathetically, while direct reports should take responsibility for their career direction and come prepared to discuss what they'd like to talk about.\n\n- An important step in setting up 1-on-1s is what's called [\"contracting\"](https://www.theengineeringmanager.com/management-101/contracting/). This involves asking the report questions about expectations:\n - \"What are the areas that you would like support with?\"\n - \"How would you like to receive feedback and support from me?\" (frequency, timing of bad news)\n - \"How confidential is the content of our meetings?\"\n- Typically, these are not status meetings, although they can be if the report encounters a lot of blockers. Status updates can be handled in other avenues (Slack, email).\n- Offer both praise and constructive criticism‚Äîfocusing on specific examples and actionable suggestions.\n - Typically, praise can be public, while criticism should be reserved for private communications. Managers can ask direct reports how they prefer to receive feedback. Some people like an async message before the 1-on-1, while others prefer to hear all feedback in person.\n - A good manager lets reports know when they screw up‚Äîthe sooner a report knows about bad habits, the easier it will be to correct. Feedback should be timely (as close to the observed action/behavior as possible), given in the form of specific examples, and depersonalized (focused on specific actions/decisions/outcomes rather than attacking any person).\n\n> \"Regular 1-on-1s are like oil changes; if you skip them, plan to get stranded on the side of the highway at the worst possible time.\"\n\n# Chapter 2: Mentoring\n\nMentoring offers a valuable opportunity for aspiring managers to safely experience the responsibilities and nuances of management, such as being responsible for another person.\n\nSeveral of the same principles as a manager/direct report relationship carry over to mentorship:\n\n- A good mentor should actively listen and communicate clearly. It's helpful if communication is done in the style of the mentee (listen and speak their language).\n- A good mentee comes prepared with what they're interested in learning.\n- New hiring/onboarding is a great time to set up a mentor/mentee relationship.\n\nThe result of a successful mentorship might include the mentor going to their network and telling folks how great the company they're working for is.\n\n# Chapter 3: Tech Lead\n\n> \"A tech lead is not a point in the career ladder, but rather a set of responsibilities that an engineer may take once they reach the senior level. This role may or may not include people management, but if it does, the tech lead is expected to manage these team members to high management standards.\"\n\nThe role may not be the most senior on the team, but it is more heavily involved in **project management** and requires effective delegation skills without resorting to micromanagement. A tech lead shifts from worrying about their own productivity to focusing more on the whole team's **productivity**.\n\nA significant part of the tech lead role involves balancing technical commitments with the broader needs of the team (project management, helping unblock teammates, and in general things that a software engineer up until this point doesn't have as much experience with and may feel less comfortable working on). If, as an IC, the SWE was spending almost 100% of their time coding, when they transition to tech lead, they might expect to code around 30% of the time.\n\nThere are a few different roles as a tech lead:\n\n- System architect / business analyst - Have a good understanding of the overall architecture and how to design complex software.\n- Project planner - Break down work into rough deliverables‚Äîgetting as much productive work ready in parallel as possible. There's a certain dogged persistence that a project planner must carry in order to \"push through the unknown\" and discover what the work requires until there's no more value to be gained from spending discovery time. A project planner might also track the project and course correct, use insights gained in the planning process to manage requirement changes, and run a pre- and postmortem.\n- Software developer/Team leader - This is the part of the role that still writes code. You'll delegate a lot of work as a tech lead, but you should still write and stay up to date with the code.\n\nA few tips to be a good tech lead:\n\n- Understand the architecture‚Äîit's impossible to lead projects when you don't understand the architecture you're changing.\n- Be a team player‚Äîa tech lead should stop themselves if they're doing all the interesting work. Working on the boring/frustrating parts of the codebase can teach you a lot about where the process is broken.\n- Lead technical decisions‚Äîhave a good sense of decisions that you must make versus what you should delegate to others with more expertise.\n- Communicate‚ÄîInstead of every team member sitting in technical meetings, you're representing them as tech lead. Bring info from those meetings back to the team.\n\n# Chapter 4: Managing People\n\n> \"It's hard to accept that a 'new manager' is an entry-level job with no seniority to any front, but that's the best mindset with which to start leading.\"\n\nWhen you're managing people, your team is only as healthy as the individuals. There are several important people management tasks like holding regular 1-on-1s, giving feedback on career growth and progression toward goals, and identifying areas for improvement. To effectively initiate a management relationship, the following specific actions are recommended:\n\n- Make time to understand the person reporting to you on a personal level.\n- Create a 30/60/90 day plan for development.\n- Try to encourage the report's participation in new hire documentation‚Äîa fresh set of eyes can see things from a different perspective than whoever created this type of team documentation.\n- Contracting (as described in 1-on-1s above)‚Äîset expectations and communication style.\n\n### Delegation\n\nA common tendency for new managers is to want to maintain control over projects and micromanage. The hardest thing about this is realizing when some projects do actually need more oversight (i.e., junior engineers who thrive under close direction). However, if you strip away too much autonomy and creative freedom from some of your direct reports via micromanagement, you could end up demotivating them, leading to a disillusionment that might be similar to burnout. There's nothing worse than feeling like every decision has to constantly be double-checked by your manager. The ideal way this book advocates to approach these situations as a manager is to think about how you delegate work. Delegation is not giving up all responsibility to reports, but rather helping them understand responsibilities and being there to support them and the project.\n\nTo delegate effectively, you need to:\n\n- Use team goals and system stability as a gauge for determining what to focus on. If systems are stable, there's little need to stay intimately involved with all details. However, a team with no clear plan might need more oversight.\n- Gather info from systems before meeting with project team members. Since the team may be having difficulty already and will be less productive if they're constantly seeking information for you, it's better to first try to pull as much data as you can.\n- Adjust your focus depending on the stage of the project‚Äîa project in its earlier stages may be more concerned with system design, while project progress will be more important for a project that's closer to its deadline.\n- Establishing a set of team standards is tremendously beneficial to allow everyone to communicate well and depersonalize the feedback process‚Äîi.e., how much unit testing, at what point does a technical decision need to involve the larger group (like adding a new system or language).\n- Allow for the open sharing of info, regardless of whether the content is good or bad. If someone is failing on a project, it's critical that they're allowed to communicate this fact early. A culture of blame will only make it more likely that people will hide this kind of info.\n\n### Continuous Feedback and Reviews\n\nContinuous feedback is a commitment to regularly share both positive and corrective feedback. For 1-on-1 manager-report relationships, the frequency and timing of this feedback is often guided by answers to the contracting questions. To be effective at giving feedback, managers need a knack for observing and understanding their team. What are the goals, strengths, and weaknesses of your reports and team members? Good managers have an intuition for identifying talents and helping people draw more out of their strengths. As an exercise, each week, you could try to identify at least one item to praise about someone on your team. Feedback should be lightweight and regular. There's also a tendency when everything is going well to just give praise, but in these scenarios, you should also strive to make suggestions about what could be even better in the future.\n\nWhile continuous feedback provides an opportunity for more frequent feedback, performance reviews are a more formal holistic approach. Typically, feedback comes from the manager, teammates, a self-review, and anyone who reports to the individual. The manager of this person will then gather all these reviews to write the manager's review. Some tips for giving performance reviews:\n\n- **Stay specific and use examples**‚Äîthis will help you write more unbiased reviews.\n - Similarly, keep areas for improvement specific‚Äîshare feedback you think is valuable and can be acted on. If there is little negative feedback, it could mean the person is ready for more challenging projects or possibly promotion.\n- If regular feedback has been given, in alignment with the continuous feedback philosophy outlined above, there should be **no big surprises in performance reviews**.\n- Give yourself enough time to write a thoughtful and considerate review. Also, give yourself enough time to talk through the review with your report(s).\n- **Try to avoid any recency biases** by accounting for the whole year rather than just the past couple of months.\n\nIf a report is a candidate for improvement, as a manager, you'll need to make the case for their improvement. You'll need to fully understand how the promotion process works at your company‚Äîand be able to be transparent with your team in explaining how this works. Part of the role of a manager is, before the promotion nominations are made, to identify promotion-worthy projects that high-achieving team members can take on.\n\n#### Handling Underperformance\n\nOne of the basic rules of management is the rule of no surprises, particularly negative ones. If regular negative feedback doesn't result in improvement, you'll likely need to create a performance improvement plan (PIP)‚Äîwhich will include a set of clearly defined objectives that a person must achieve within a fixed period of time. You typically want a record of all negative feedback you've given prior to (and during) the PIP in case the employee isn't able to improve according to their plan and you need to escalate to a firing, which will usually be handled by HR. You typically don't want to put anyone on a plan whom you wouldn't be happy to lose.\n\nAnother difficult situation arises when you believe that your team is not the right place for your report to grow their career. In this instance, some managers will \"coach their report out\" or encourage them to grow their career in another part of the organization. You're not technically firing them, but you are giving them time and space to find something more suited for them.\n\n# Chapter 5: Managing a Team\n\nThe report manager relationship is largely similar when you're managing one or multiple people, however when you start managing a team there is a totally different set of requirements and challenges. The book describes a team manager as an `engineering lead` - in this role there is less time spent writing code but team managers still engage in small technical deliverables (bug fixes, small features) without blocking/slowing the progress of their team. It's not just writing code anymore though, it's identifying bottlenecks and removing blockers for their teams success. A good team manager isn't about having technical knowledge, although that helps, the work of supporting people is far more important to management success.\n\nThe team manager will often help identify the most high-value projects and keep their team focused on these projects - this involves partnering closely with the product lead to ensure deliverables are met. Part of the management role also includes identifying headcount and other recruiting needs. This role also includes managing the technical roadmap for their product group, communicating timeline, scope and risks to their product/group pillar partners, identifying tech debt, doing cost benefit analysis for resolving debt, and helping communicate timelines for prioritizing this to the management team.\n\n### Staying Technical\n\nEngineering management is people skills plus technical discipline. Your technical instinct should have been honed over years of doing the job. If you want to command the respect of the engineering team, they must see you as technically credible (otherwise you're facing an uphill battle). If you don't stay in the code, you risk becoming technically obsolete too early in your career (staying in the code helps you see where the bottlenecks and process problems are). A good manager can identify the shortest path through systems to implement new features.\n\n### Debugging Dysfunction\n\nSometimes teams continually miss deliverables, people are unhappy, product managers are frustrated, and your attrition rate rises. If you're not entirely sure what the issue is, there are a few steps you can take to debug the root causes:\n\n- **Not shipping** - As a manager you'll need to push for the removal of bottlenecks (i.e.,.. hold the team accountable for more frequent releases). When people are contending for scarce resources, conflicts and unhappiness among team members are common and inevitable. As a manager you can spend more time coding in this scenario.\n- **People drama** - Make it clear bad behavior has to change. Providing clear examples and corrective feedback quickly after events happen may be the best defense against such conflict. Quick action is essential.\n- **Burnout** - Identifying a root cause of overworked employees can help here. For example, if an unstable prod system causes engineers to be constantly fighting fires, your job as manager is to slow down the product roadmap to focus more on stability (and technical debt - 20% rule). Try to use metrics around downtime and incidents to help inform action plans to reduce them. For time-critical releases, as a manager, you'll need to play cheerleader here and help out with the work at times. Be appreciative (continuous feedback) of your team during periods you know have been difficult, offering breaks, while making the process as enjoyable (or even fun) as it can be.\n- **Collaboration problems** - If your team isn't working well cross-functionally (with design, product, or another tech team), you'll want to meet with management and other peers to understand and work through issues. If the teams aren't working well together, look into creating some opportunities for them to hang out (short game time maybe?).\n\n### Driving Good Decisions\n\nThe engineering manager is usually accountable for the team's progress. There are a few tips outlined for how to drive decisions, since as a manager you may only have authority to guide decisions rather than dictate them, however you'll still be judged on the ultimate outcome.\n\n- **data-driven team culture** - create a habit of giving the product/business data about the team velocity, quality measures (outages, bugs found, etc...). Even the 4 DORA metrics could be useful here (deployment frequency, lead time to changes, mean time to recovery, change failure rate)\n- **Flex your product muscles** - It's important to develop customer empathy to give your engineers context for your work\n- **Thinking ahead** - Thinking about where the product roadmap is going can help you guide the technical roadmap. Ask the product team questions about the future, and spend some time keeping up with technology developments that might impact the way you think about software or how you're operating\n- **Review the outcome of decisions and projects** - review assumptions made after the project is done (done at the scrum team level with retros)\n- **Run retros for the processes and day to day** - discuss what happened during the sprint and pick a few events (good, bad, and neutral to discuss in detail)\n\n### Conflict Management\n\nHave a team that's constantly in disagreement can be painful and dysfunctional - however on the other end of the spectrum is artificial harmony where everyone just agrees for the sake of agreeing, even though they're unhappy with decisions being made. The key is to create a safe environment for disagreement to work itself out, which is far better than pretending that all disagreement does not exist.\n\n- **Don't rely on consensus voting** - well established teams can predict the direction of a decision, so it's best not to set people up for a vote you know will go certain way. It's better to deliver bad news yourself\n- **Setup processes to depersonalize** - start with a shared understanding of goals, risks, and questions that go into making a decision.\n- **Don't turn a blind eye to simmering issues** - If you don't pay close enough attention, issues will go on for way too long to a point where they're difficult to address\n- **Don't take it out on other teams**\n- **Be kind** - You do'nt need to be overly \"nice\" (\"please\" and \"thank you\"). Being kind is telling someone who isn't ready for promotion that she isn't ready\n- **Don't be afraid of conflict** - It's natural to be worried about making people upset with a decision - this is OK. It's however a wise habit to be sensitive to the outcomes of a conflict\n- **Be curious about your own actions** - \"Am I pushing decisions to the team because I don't want to deal with it as an engineering manager?\" \"Am I avoiding working through the issues with my peer because their difficult to work with?\"\n\n### Engineering Manager Project Management\n\nAs an engineering manager, you're responsible for the larger picture planning. While tech leads/devs are planning in terms of weeks, as manager, you should be planning higher level in terms of months. Some rough guidelines include:\n\n- Budgeting 20% of your time for sustaining engineer work (testing, debugging, tech debt, migrating versions etc...).\n- Budget roughly 10 productive engineering weeks per quarter (with PTO/holidays)\n- Understand your \"must-haves\" versus \"nice-to-haves\" and be willing to say no to things\n- Use the doubling rule for estimates - when asked for estimates, double what you would guess it would take\n\n# Chapter 6: Managing Multiple Teams\n\nAdvancing in the management track, particularly to the role of a Director of Engineering, often leads to managing multiple teams - at this point you'll likely have multiple tech leads reporting to you.\n\n### Proper time management\n\n> When you have so many management duties that you have little time to code, you can start to feel like your day has been taken hostage by the whims of others\n\nYou'll need to carefully consider how you manage your time at this level of management. This often comes down to understanding the importance and urgency of the matter. Tasks that are both important and urgent are ones you'll definitely need to prioritize, but there may be several distractions each day that seem urgent, but are in fact not.\n\n| | Not Urgent | Urgent |\n| --------------- | -------------------- | --------------------- |\n| **Important** | Strategic, make time | Obvious Work |\n| **Unimportant** | Obvious avoid | Tempting distractions |\n\n> As you navigate your new obligations, start to ask yourself: How important is the thing I‚Äôm doing? Does it seem to be important because it‚Äôs urgent?\n\n#### Delegation to reduce plate-spinning\n\nA related topic to time management is the process of delegation. The book uses \"plate-spinning\" as an analogy of management, where you have a bunch of plates on different poles, and you must attend to each spinning plate before it slows down and falls off. You have to develop good instinct to anticipate when certain plates stop spinning (teams get burnt out, or processes need improvement). The only way to not feel overwhelmed by all the plate-spinning is to effectively delegate tasks:\n\n| | Frequent | Infrequent |\n| ----------- | ----------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------- |\n| **Simple** | **Delegate** (running daily standups, writing a weekly summary of progress, conducting code reviews) | **Do it yourself** (booking occasional conference tickets, running the quarterly script) |\n| **Complex** | **Delegate carefully** (grow talent in areas like project planning, system design, or outage/incident management) | **Delegate for training purposes** (have a tech lead sit with you to write performance reviews, project staffing planning) |\n\n> Delegation is a process that starts slow but turns into an essential element for career growth. If your teams can‚Äôt operate well without you, you‚Äôll find it hard to be promoted.\n\n#### Saying No\n\nBeing able to say no is also a useful strategy with respect to time management and finding the most impactful work to do:\n\n- **Yes we can do this project if we delay the start of the other**\n- **Appeal to budget** - lay out current workload in plain terms, showing how little room there is to maneuver\n- **Don't drag out a no answer** - Sometimes it's better to say no more quickly than to drag out such a response - if you're wrong you'll need to apologize for the mistake\n- **Help me say yes** - If you dig into (and question) the parts of someone else's plan that seem questionable, you'll help the other person realize that their suggestion isn't a good idea or needs refinement\n\n### Creating a durable shared team identity\n\nCreating a shared team identity is difficult and it is easy to focus too internally on the team, leading the team to feel superior to others in the organization. If the team goes too far in this direction it can become resistant to outside ideas, be a poor at adapting to organization changes, and be too focused on empire building. Whereas a team that is more committed to the company's mission fosters resilience that leads to an openness to innovation, prioritizing company-wide objectives over team goals, and adaptability.\n\nCreating durable teams requires aligning with the company's core values and mission. In less well defined environments like startups, these missions can be fuzzy and you'll need to think about setting up teams to work well within a larger picture and mission.\n\n# Chapter 7: Managing Managers\n\nManaging managers shares many similarities with managing multiple teams, including several of the same responsibilities of overseeing the health of your direct reports' teams. There is however an increased scope when you're managing managers - instead of managing a couple closely related teams, you're now managing possibly whole functions like engineering and operations (areas you may not be as familiar with) - and you're responsible for the health of those teams. It becomes easy to miss details when you're no longer meeting with just ICs.\n\nSome tips to maintain healthy teams with this increased scope:\n\n- **Open door policy fallacy** - It's easy to think you can have an open door policy for ICs to escalate issues to you. However most engineers won't be brave enough to take the risk of talking about problems. Instead you'll need to evaluate the health of your direct reports' teams - ideally via 1on1s with your direct report managers (these will need to be real conversations that should identify any attrition, failure to ship or other issues that reflect back to you as the higher-level manager)\n- **Skip-level meetings** - help get perspective on the health and focus of your teams and develop personal relationships between you and everyone in the organization. Can be as frequent as once a quarter.\n - Some prompts might include : What do you like best or least about your project? Who has been doing well? Feedback about their manager? How do you see the whole organization doing? What's keeping you from doing your best work?\n\n#### Manager Accountability\n\nThe primary role of a manger who oversees other managers is to ensure these direct reports are effectively leading their team and aligning within the organization's broader goals.\n\nIt's common for managers to excel at managing up and to hide problems until they become unwieldy. While this may make your life as a manager's manager easier in the short term, it's better to hold them to account as soon as you get a hint of any issue. Part of this is having your managers keep track of the health of their teams. Your role might also involve navigating complex situations where your direct reports are managing issues with tech leads or product managers - where the lines of responsibility are less clear.\n\nThere are several possibly tricky issues that managers of teams should be held to account for:\n\n- **Unstable product roadmaps** - Managers of teams should address rapidly changing roadmap (which can lead to attrition)\n- **Errant tech leads** - Managers need to guide tech leads to ensure design processes are efficient/transparent - possibly involving other senior team members\n- **Constant firefighting** - Managers should develop plans to tackle underlying issues that cause frequent crises - and possibly consider requesting additional resources\n\nAs a higher level manager you are responsible for supporting and developing these managers. You should provide support in cases where your direct report may not have as much influence, or in hiring decisions. You should also provide ample feedback that focuses on both strengths and weaknesses that you can identify. If you're able to improve the performance of your direct report managers, this can significantly impact the organization's success, and by extension your own reputation and effectiveness as the overseeing manager.\n\n#### People pleaser management flaws\n\nPeople pleaser managers can develop a deep aversion to making people they care about unhappy and will often say yes, possibly leading to their own burnout. The team may like this type of manager on a personal level, but be frustrated with them as a manager. This manager never pushes back on work, overpromises and underdelivers, and says yes to everyone which can send contradictory messages. The manager is more interested in a team that runs smoothly and avoids mistakes than a team that really becomes excellent. Worse yet, if the manager has fears of failure or rejection, it can make it harder for the team to fail in a healthy way. Promises can be made that are hard to keep and make the team bitter toward the manager or company. If you have a direct report manager displaying these characteristics, you'll want to highlight the downsides to exhibiting this behavior.\n\nSome tips to coach this type of manager include:\n\n- help them feel safe saying no\n- have them externalize decisions so more people take part in the decisioning process (if it fails it's a team failure)\n- provide the person strong partners who can take on the task of determining the work roadmap\n- focus on better processes - allowing the manager to point to these processes as something outside their control\n\n#### Managing New vs Experienced Managers\n\nFirst-time managers need a lot of coaching, but it's an up-front cost that pays long-term dividends. Some common coaching you might need to do is ensure this manager is effective at delegating work, ensure they're not taking the job for just the authority, make sure you're doing skip levels to understand the health of the team, and as mentioned earlier, holding the manager accountable so issues aren't spiraling out of control. You want to nominate the right person for the role of a manager - if it turns out a new manager doesn't belong in that role you generally don't want to keep them in that position.\n\nBringing in experienced managers is slightly different - since management is such a culture-specific task in a company, you'll want to ensure they fit with the wider company culture. It's not just skills you're hiring for, you'll want to bring in a software engineering manager who has worked with teams, knows how to ship software frequently, is comfortable with modern dev practices, and can inspire creativity with engineers. The hiring process for these managers could include mock problem solving with actual employees who might be the new hire's direct reports. While there could be coding in interviews for managers, you're also looking for strong team debugging skills, and ensure they have had a successful management philosophy (staying in code, breaking problems down, observing with data). Reference checks could also be valuable in the hiring process, where you ask how this person has succeeded and failed working with the reference.\n\n#### Debugging Dysfunctional Teams\n\nThe best engineering managers are great debuggers - relentless in the pursuit of why. The book describes managing teams as a series of complex black boxes interacting with other black boxes - when you encounter outputs that aren't as expected you'll need to figure out why by \"opening up boxes\" to see what's going on.\n\nPossible team debugging steps:\n\n- Have a hypothesis for how the system got into a failed state\n- **Observe the team** - sit in the team's meetings. Good meetings have a heavy discussion element where opinions are drawn out of the team. A boring meeting may be a sign of an issue\n- **Ask questions** - ask the team what their goals are to see if they have a clearly defined purpose\n- **Check team dynamics** - teams that run smoothly typically have a degree of personal connection between the members. If team members are working independently on different projects, they're not really working as a team\n- **Jump in to help** - its ok to jump in and help debug - particularly when the new manager in question is struggling\n\n#### Staying Technically Relevant\n\nWithout investment into technical skills, managers run the risk of becoming out of touch and obsolete. There are ways to stay relevant such as reading code (reviewing PRs), picking an unknown area and ask engineers to explain, attend postmortem/retros, keep up with industry trends, and maintaining a network of technical people. By staying relevant in technical areas you provide specific values to teams - you help the team stay accountable to where it places its energy, you're able to identify misguided efforts by asking informed questions, you're able to analyze the engineering and business tradeoffs, and you'll be able to make specific requests to teams without distracting\n\n> Managers who don‚Äôt stay technical enough sometimes find themselves in the\n> bad habit of acting as a go-between for senior management and their teams.\n> Instead of filtering requests, they relay them to the team and then relay the\n> team‚Äôs response back up to management. This is not a value-added role\n\n# Chapter 8: The Big Leagues\n\n> As technical senior managers, we bring special skills to an organization. In particular, we bring a willingness to embrace and drive changes as needed. ... We understand that technology evolves quickly, and we want our organizations to evolve to keep up with these changes. ... It's not enough to be a change agent; we have to create an organization that can successfully follow through on the changes we want to push.\n\nRoles such as CTO, VP, and Head of Engineering extend beyond being a positive technical force; they also encompass leadership, understanding the current and future business landscape, making hard decisions without perfect information, understanding how to play politics in a productive way, and a willingness to still deliver on decisions you disagree with. There are a few categories of tasks that any general manager might take on (from the High Output Management book):\n\n- **Info Gathering/Sharing** - Sitting in meetings, reading/writing emails/slack messages, talking to people one on one, and gathering perspectives. The goal is to synthesize large quantities of info, teasing out critical pieces\n- **Nudging** - Reminding people of their commitments by asking questions instead of giving orders. It's easier to nudge by asking questions that guide a team rather than more forceful suggestions\n- **Decision making** - One of the difficult aspects of management - managers must take different perspectives and incomplete info, and make a decision where the impact affects you and the team\n- **Role modeling** - Setting the best example for the team\n\n#### VP of Engineering vs CTO\n\n| Aspect | VP of Engineering | CTO |\n| -------------------------- | ------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **Position in Management** | Top of the management career for engineering | Executive first, technologist second |\n| **Focus** | Detail-oriented and able to handle both high-level and low-level tasks | Larger, strategic overview of technology in the company |\n| **Responsibilities** | Roadmap development, hiring planning, org strategy, people management, improving engineering process, and cross-functional partnering | Positioning technology in the company, strategic technical decisions, oversee architecture and process/guidelines for evolving it, go deep into understanding biz side, external events and speaking engagements |\n\n### Setting Strategy\n\nSetting strategy is likely an area that most newer big league managers might not be skilled at. The book offers a few tips here:\n\n- **Research** - understand the current and future scaling issues, current productivity bottlenecks, pain points of the current tech, where growth will come from\n- **Combine research with your ideas** - draw out systems at company and slice/dice across various common attributes. i.e., looking at systems that are customer facing (customer service tools) vs systems that are internal operations-facing (warehouses)\n- **Draft a strategy** - actionable ideas to improve operational efficiency and expand features and grow the business\n- **Consider boards communication style** - Presentation style matters. Some boards read deck materials beforehand, in which case you should have a deck that includes valuable info\n\n> ...good technology here meant several things. It meant technology architectures, yes. It also meant team structure. It meant understanding the underpinnings of the business and the directions in which it was headed. ... for product-focus companies ... something that \"enables the many potential futures of the business.\" It's not just a reactive document that tries to account for current problems, but it anticipates and enables future growth.\n\n### Tips for Dealing with Nontechnical Bosses\n\nWhen you work in engineering for a longer period of time with technical managers, suddenly having a nontechnical boss can be a bit jarring, but there are a few best practices to manage this specific relationship:\n\n- **Don't hide info behind jargon**\n- **Expect you will need to lead 1on1s** - come prepared with a list of topics\n- **Try to bring solutions, not problems**\n- **It's OK to ask for advice**\n- **Don't be afraid to repeat yourself in communication** - most people remember things after hearing it from others 3 times\n- **Be supportive** - ask if there's more you can do to help\n- **Seek out coaching and skill development elsewhere** - your boss likely won't be able to help you here, so you'll need to seek out other peers or even look outside the company for support\n\n### Detaching as a Senior Leader\n\nAs a senior leader your days of socializing with your team outside working hours is a thing of the past. You must learn to detach, otherwise you risk being seen as playing favorites if you maintain strong social ties with team members.\n\n- **Be a good role model** - As a senior leader, you'll likely be watched more closely than you ever have before - a lot of employees with follow every little behavior or small thing you say. Your presence will change the tone and structure of meetings you attend.\n- **Making hard decisions** - There are times you won‚Äôt discuss hard decisions with others, and you also shouldn‚Äôt rant about them to teammates\n- **Care more about people as individuals** - At this level, it can be easy to treat them like cogs, so you'll want to take the time to get to know as many people as you can as humans. This kind of personalization will be noticed.\n\n### Correcting a Culture of Fear\n\nIt's easy for fear to propagate amongst the team when managers are quick to criticism, visibly upset, or otherwise easily display negative emotions. This can lead to a loss of psychological safety and willingness to take risks amongst the team. Healthy teams should be independent, willing to take risks, and free to push themselves. There's also typically open debate to resolve conflict amongst engineers as peers, but when you as a senior manager are debating, others may be more fearful to speak up. There are a few tips in this case to correct a culture of fear:\n\n- **Practice relatedness** - A marker of fear might be the tendency to treat people impersonally. Be willing to engage in small talk and getting to know the team as people.\n- **Apologize when you screw up** - Model that it's ok to make mistakes, it doesn't make you weak\n- **Get curious** - It's much easier to approach a disagreement with curiosity, which can turn disagreement into honest questioning\n- **Hold people accountable without making them out as bad** - When you hold your team accountable for not meeting expectation, make sure you understand how your framing things - asking questions like \"How do we measure success in this scenario?\", or \"Did I set the team up for success\n\n# Chapter 9: Bootstrapping Culture\n\n> Where you are growing a new team or reforming an existing team, neglecting team culture is a sure-fire way to make your job harder. As the team grows and evolves, it's important to attend to your culture as you would attend to other important pieces of infrastructure that you rely on.\n\nEffective leaders possess the ability to identify and shape underlying system structures and team dynamics, and it's important that they take action in these areas in a way that support long-term goals. The book emphasizes the importance of choosing systems that guide us toward our next milestone and facilitate learning from the successes and failures of these processes and structures, rather than perceiving 'structure and processes' as hindrances to development, a common thought in agile, scrappy startup cultures. It's better to choose an imperfect system early on and learn from it then be paralyzed by such a decision and have the company scale out without any systems or processes.\n\n### Assessing your role\n\nWhen setting up structure and processes, it's important to understand the size of the ship (your company) that you, as a leader, are steering. This can be determined through some of the following characteristics:\n\n- **People** - leaders who want a high degree of control over their org tend to need more structure in place to ensure their wishes are enacted\n- **Age** - the longer a company is around, the more habits become entrenched (and the more likely it is to continue to survive)\n- **Size of existing infrasturcutre** - the less business rules, code, and infrastructure there is, the less the need for structure (and vice versa)\n- **Risk tolerance** - Are you in a highly regulated industry? Do you have a lot to lose if certain mistakes are made? Structures and processes should reflect this\n\n### What is Culture\n\n> Culture is how things get down, without people having to think about it.\n\nCulture is the unspoken shared rules of a community. It doesn't mean every person needs to hold the exact same values, but it tends to guide a general overlap. In more complex environments where the needs of the group must override the needs of the individual, cultural values are the glue that enables us to work as a team.\n\n- To reinforce culture, you can reward people for exhibiting its values in positive ways (i.e.,. in performance reviews). You can learn to spot people The stories that we tell as a community bond us together.\n- Learn to spot people who have value conflicts with the company/team. Be willing to coach people in areas where they're misaligned\n- You'll want to look for culture fit in interviews, but culture fit is not about hiring friends (this won't lead to the strongest teams)\n\n### Cultural Policy Documents\n\nDrafting cultural policy documents is likely not the more coveted role of managers, but fortunately there are fewer and fewer of these types of docs that need to be started from scratch - many are shared publicly online. You typically want to add structure, such as policy documents, when things are failing.\n\n#### Cultural Policy Document Example - Writing a career ladder\n\nIf there's inconsistencies around what HR should pay new hires, or how long it\nSome tips for writing a career ladder include:\n\n- **Look for examples from other companies**\n- **Solicit support from your team** - senior managers and engineers can provide feedback and details\n- **Provide more early opportunities for advancement** - You may want to promote early career employees every year for the first two to three years of their career.\n- **Use narrow salary bands for early-career stages** that allow for quick promotion, use wider bands when you have fewer levels.\n - You want salary bands to overlap - i.e., Jr SWE 50-100k, Sr Swe 80-150k. This allows you to retain talent who are performing well at their current level but not ready to take on the additional responsibility at the next level. This also lets you hire people who are on the fence into the lower level with the expectation of a quick promotion.\n- **Consider breakpoint levels** - The \"breakpoint level\" is the lowest level at which people can sit forever (never getting promoted but also not underperforming). Expect your team to cluster around this level, with fewer people above or below it\n- **Celebrate and share keystone promotions**\n- **Split management and technical tracks**\n- **Consider making people management skills a mid-career requirement** - similarly, a tech lead might be a requirement of a senior IC on the technical track\n- **Years of experience** - Distinguish levels by an expectation of maturity increase, typically this corresponds with YOE\n- **Don't be afraid to evolve over time** - a ladder should be a living document that evolves as the company grows\n\n### Cross Functional vs Engineering Focused Teams\n\nIn a small company or startup, it's clear that the engineering team is working with pretty much everyone, be it product managers, designers, etc.... In a larger company, there's likely already a structure setup to facilitate roles and cross functional collaboration. The book suggests that engineers be directly on a \"pod\"/team with product managers and designers, as this often leads to effective product development and iteration. Typically in pods, engineers with the best product sense emerge as leaders. Engineering still needs to oversee critical core systems - these functions can be kept in a small infrastructure organization that does not need to be assigned to product development.\n\nIt's important for engineering teams, even those assigned with product teams, to still devote 20% of their time for sustaining tasks (interviewing, tech-deb,t on-call).\n\n### Engineering Processes to add as a team grows\n\nThere are 3 major processes you should consider formalizing as the team grows - each work best with behavioral expectations around them (in addition to technical details):\n\n- **Code review** - largely a socialization exercise so multiple team members have seen and are aware of changed code. Typically bugs are caught via the test suite and less likely to be caught in peer code reviews\n - use a linter to resolve style issues\n - limit how many outstanding review requests a person can have assigned to them (Github round robin and load balancing)\n- **Outage postmortems**\n - resist the urge to point fingers\n - look at circumstances and understand context to help identify root cause\n - determine which takeaways are important - there should be one or two truly high-risk glaring issues that could cause future problems\n- **Architecture review** - help socialize big changes to the appropriate group, and make the risk for those changes clear.\n - Architecture questions - How many people on the team are comfortable using the new system? What's the process for rolling it out? Are there new operational considerations?\n - be specific about the kinds of changes that need architecture review (new languages/frameworks, storage systems, new dev tooling)\n - process of preparing for architecture review is important - forces people to carefully consider why they want to make these changes\n - choose the review board wisely - should be those most closely impacted by decision\n\n# Conclusion\n\nReflecting on the extensive insights provided in 'The Manager's Path,' the transition from mentor to executive emerges as both a challenging and rewarding journey. One of the takeaways of the book is the importance of being self-aware for effective leadership. As a manager, you'll need to understand your own reactions, inspirations, and frustrations in order to manage others well. You'll also need to cultivate curiosity (the author suggests daily free-writing here as a way to remind yourself to stay curious) - curiosity helps understand various perspectives, particularly in challenging interpersonal situations.\n\n## Resources\n\n- [The Manager's Path Summary - Runn.io Blog](https://www.runn.io/blog/the-managers-path-summary)\n- [Learning Notes on The Manager's Path - GitHub](https://github.com/keyvanakbary/learning-notes/blob/master/books/the-managers-path.md)\n- [The Manager's Path Book Summary - Dan Lebrero's Blog](https://danlebrero.com/2020/07/22/the-managers-path-book-summary/)\n- [The Engineering Manager](https://www.theengineeringmanager.com/)"
    }
  ],
  "generatedAt": "2026-01-24T21:09:44.395Z"
}